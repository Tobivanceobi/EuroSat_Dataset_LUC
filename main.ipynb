{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Load the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c96e1dbd152f98"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-30T13:16:45.717174Z",
     "start_time": "2024-03-30T13:16:41.227928Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "from src.training.pretrainedModels import get_pretrained_model\n",
    "from src.colors import bcolors\n",
    "from config import Config\n",
    "\n",
    "c = bcolors()\n",
    "config = Config()\n",
    "PRETRAINED_MODEL = \"vit_b_16\""
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    Resize(output_size=256, p=1.0, p_batch=1.0, same_on_batch=True, size=256, side=short, resample=bilinear, align_corners=True, antialias=False)\n",
      "    CenterCrop(p=1.0, p_batch=1.0, same_on_batch=True, resample=bilinear, cropping_mode=slice, align_corners=True, size=(224, 224), padding_mode=zeros)\n",
      "    Normalize(p=1.0, p_batch=1.0, same_on_batch=True, mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "\n",
    "from src.training.pretrainedModels import get_pretrained_model\n",
    "from src.pickle_loader import save_object\n",
    "\n",
    "CHANNELS_2C = [3, 2, 1]\n",
    "CHANNELS_2A = [3, 2, 1]\n",
    "NUM_CLASSES = 10\n",
    "NUM_AUG = 1\n",
    "\n",
    "_, transform = get_pretrained_model(PRETRAINED_MODEL)\n",
    "\n",
    "df = pd.read_csv(config.TRAIN_FILE)\n",
    "\n",
    "df_test = pd.read_csv(\"labels.csv\")\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "encoder = encoder.fit(df[['label']].values.reshape(-1, 1))\n",
    "save_object(encoder, config.DATA_DIR + \"on_hot_encoder\")\n",
    "print(transform)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T13:16:55.876704Z",
     "start_time": "2024-03-30T13:16:54.554663Z"
    }
   },
   "id": "ea2db869e77d2168",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "mean_std_S2C = {\n",
    "    'mean': [1373.1, 1322.3, 1397.6],\n",
    "    'std': [1144.9, 878.7, 854.3]\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T13:16:57.221256Z",
     "start_time": "2024-03-30T13:16:57.217181Z"
    }
   },
   "id": "2c4cc1cffbc2ac9c",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AnnualCrop' 'Forest' 'HerbaceousVegetation' 'Highway' 'Industrial'\n",
      " 'Pasture' 'PermanentCrop' 'Residential' 'River' 'SeaLake']\n",
      "\n",
      "\u001B[92mPreloading images...\u001B[0m\n",
      "\n",
      "\u001B[96mImages:         25920\u001B[0m\n",
      "\u001B[96mAugmentations:  25920\u001B[0m\n",
      "\u001B[96mJobs:           -4 \u001B[0m\n",
      "\n",
      "\u001B[94mTime taken:      0 min 22.490834951400757 sec \u001B[0m\n",
      "\n",
      "\u001B[92mPreloading images...\u001B[0m\n",
      "\n",
      "\u001B[96mImages:         1003\u001B[0m\n",
      "\u001B[96mAugmentations:  1003\u001B[0m\n",
      "\u001B[96mJobs:           -4 \u001B[0m\n",
      "\n",
      "\u001B[94mTime taken:      0 min 0.46628642082214355 sec \u001B[0m\n",
      "\n",
      "\u001B[92mPreloading images...\u001B[0m\n",
      "\n",
      "\u001B[96mImages:         1080\u001B[0m\n",
      "\u001B[96mAugmentations:  1080\u001B[0m\n",
      "\u001B[96mJobs:           -4 \u001B[0m\n",
      "\n",
      "\u001B[94mTime taken:      0 min 0.8866140842437744 sec \u001B[0m\n",
      "\n",
      "\u001B[92mTrain dataset:      25920 samples\u001B[0m\n",
      "\u001B[92mValidation dataset: 1003 samples\u001B[0m\n",
      "\u001B[92mTest dataset:       1080 samples\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from src.datasets.EuroSatMS import EuroSatMS\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.04, stratify=df['label'])\n",
    "print(df['label'].unique())\n",
    "\n",
    "ds_train = EuroSatMS(\n",
    "    train_df, \n",
    "    config.TRAIN_MS_DIR,\n",
    "    encoder=encoder,\n",
    "    num_aug=NUM_AUG, \n",
    "    select_chan=CHANNELS_2C,\n",
    "    transform=transform,\n",
    "    mean_std=mean_std_S2C\n",
    ")\n",
    "\n",
    "ds_val = EuroSatMS(\n",
    "    df_test, \n",
    "    config.TEST_MS_DIR,\n",
    "    encoder=encoder,\n",
    "    num_aug=NUM_AUG, \n",
    "    select_chan=CHANNELS_2A,\n",
    "    transform=transform,\n",
    "    mean_std=mean_std_S2C\n",
    ")\n",
    "\n",
    "ds_test = EuroSatMS(\n",
    "    val_df, \n",
    "    config.TRAIN_MS_DIR,\n",
    "    encoder=encoder,\n",
    "    num_aug=NUM_AUG, \n",
    "    select_chan=CHANNELS_2C,\n",
    "    transform=transform,\n",
    "    mean_std=mean_std_S2C\n",
    ")\n",
    "\n",
    "print(f\"\"\"\\n{c.OKGREEN}Train dataset:      {len(ds_train)} samples{c.ENDC}\"\"\")\n",
    "print(f\"\"\"{c.OKGREEN}Validation dataset: {len(ds_val)} samples{c.ENDC}\"\"\")\n",
    "print(f\"\"\"{c.OKGREEN}Test dataset:       {len(ds_test)} samples{c.ENDC}\"\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T13:17:22.481967Z",
     "start_time": "2024-03-30T13:16:58.549434Z"
    }
   },
   "id": "89850dd26de91e3a",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.6035, -1.5611, -1.4862,  ..., -0.6051, -0.4419, -0.2927],\n",
      "        [-1.5299, -1.4805, -1.3986,  ..., -0.4861, -0.3074, -0.1430],\n",
      "        [-1.4323, -1.3703, -1.2763,  ..., -0.3492, -0.1565,  0.0199],\n",
      "        ...,\n",
      "        [-0.8893, -0.9173, -0.9587,  ..., -1.5494, -1.5523, -1.5631],\n",
      "        [-0.9660, -1.0002, -1.0487,  ..., -1.4931, -1.4859, -1.4898],\n",
      "        [-1.0228, -1.0610, -1.1132,  ..., -1.4530, -1.4367, -1.4339]])\n",
      "[[[0.53968257 0.53968257 0.6825397  ... 0.46825397 0.46825397 0.34126985]\n",
      "  [0.53968257 0.53968257 0.6825397  ... 0.46825397 0.46825397 0.34126985]\n",
      "  [0.5        0.5        0.50793654 ... 0.52380955 0.61904764 0.3809524 ]\n",
      "  ...\n",
      "  [0.         0.         0.16666667 ... 0.8492063  0.8095238  0.76984125]\n",
      "  [0.06349207 0.06349207 0.11111111 ... 0.7936508  0.6984127  0.71428573]\n",
      "  [0.06349207 0.06349207 0.16666667 ... 0.76984125 0.73015875 0.8333333 ]]\n",
      "\n",
      " [[0.63       0.63       0.58       ... 0.43       0.45       0.37      ]\n",
      "  [0.63       0.63       0.58       ... 0.43       0.45       0.37      ]\n",
      "  [0.8        0.8        0.64       ... 0.36       0.28       0.39      ]\n",
      "  ...\n",
      "  [0.14       0.14       0.05       ... 0.7        0.62       0.62      ]\n",
      "  [0.13       0.13       0.26       ... 0.69       0.68       0.79      ]\n",
      "  [0.24       0.24       0.27       ... 0.76       0.75       0.77      ]]\n",
      "\n",
      " [[0.6        0.6        0.8        ... 0.35       0.63       0.46      ]\n",
      "  [0.6        0.6        0.8        ... 0.35       0.63       0.46      ]\n",
      "  [0.6        0.6        0.75       ... 0.41       0.49       0.32      ]\n",
      "  ...\n",
      "  [0.26       0.26       0.26       ... 0.69       1.         0.67      ]\n",
      "  [0.33       0.33       0.37       ... 0.66       0.78       0.68      ]\n",
      "  [0.18       0.18       0.2        ... 0.83       0.71       0.78      ]]]\n",
      "torch.Size([3, 224, 224])\n",
      "[-0.9697299   0.2512123  -0.31919813]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "ii = ds_test[0][0]\n",
    "\n",
    "print(ii[0])\n",
    "print(ds_train.process_image(0)[0])\n",
    "\n",
    "print(ii.shape)\n",
    "print(np.mean(ii.numpy(), axis=(1, 2)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T13:17:25.299398Z",
     "start_time": "2024-03-30T13:17:25.265829Z"
    }
   },
   "id": "84d2148e7e6e55f3",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from kornia.constants import Resample\n",
    "import kornia.augmentation as K\n",
    "from torch import nn\n",
    "\n",
    "p1, p2, p3 = 0.6, 0.75, 0.4\n",
    "augmentation = nn.Sequential(\n",
    "    K.RandomHorizontalFlip(p=p1),\n",
    "    K.RandomVerticalFlip(p=p1),\n",
    "    K.RandomAffine(degrees=30, translate=None, scale=None, shear=None, resample=\"nearest\", padding_mode=2, p=p2),\n",
    "    K.RandomShear(shear=0.2, resample=\"nearest\", padding_mode=2, p=p2),\n",
    "    K.RandomBrightness((0.5, 1.5), p=p2),\n",
    "    # K.RandomContrast(contrast=(0.85, 1.15), p=p2),\n",
    "    K.RandomSaturation((0.8, 1.2), p=p3),\n",
    "    # K.RandomPlasmaContrast(roughness=(0.01, 0.15), p=p3),\n",
    "    # K.RandomSolarize(thresholds=0.1, p=p3),\n",
    "    # K.RandomSharpness(sharpness=(0.1, 0.3), p=p3),\n",
    "    # K.RandomBoxBlur(kernel_size=(3, 3), p=p1),\n",
    "    # K.RandomEqualize(p=p1),\n",
    "    K.CenterCrop(size=(64, 64)),\n",
    ")\n",
    "\n",
    "ds_train.augment = augmentation\n",
    "ds_val.augment = None\n",
    "ds_test.augment = None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T13:17:26.374652Z",
     "start_time": "2024-03-30T13:17:26.366042Z"
    }
   },
   "id": "a5e5a55b27ee411",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CNN Model Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "693660b793045e2a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from src.training.data import EuroSatDataModule\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "data_module = EuroSatDataModule(ds_train, ds_val, ds_test, BATCH_SIZE)\n",
    "print(f\"\"\"{c.OKGREEN}Initialized the data module...{c.ENDC}\"\"\")\n",
    "\n",
    "KERNEL_SIZE = [5, 3]\n",
    "LEARNING_RATE = 0.03\n",
    "MOMENTUM = 0.9\n",
    "GAMMA = 0.9\n",
    "DROPOUT = 0.3\n",
    "EPOCHS = 15\n",
    "CKPT_PATH = 'checkpoints/cnn/'\n",
    "CLASS_WEIGHTS = {'AnnualCrop': 9,\n",
    "                 'Forest': 9,\n",
    "                 'HerbaceousVegetation': 8, \n",
    "                 'Highway': 9, \n",
    "                 'Industrial': 9,\n",
    "                 'Pasture': 9, \n",
    "                 'PermanentCrop': 9, \n",
    "                 'Residential': 9, \n",
    "                 'River': 9, \n",
    "                 'SeaLake': 9}\n",
    "\n",
    "w = np.array(list(CLASS_WEIGHTS.values()))\n",
    "w_min, w_max = w.min(), w.max()\n",
    "w = (w - w_min) / (w_max - w_min)\n",
    "\n",
    "fname = \"cnn_c\"\n",
    "for c in CHANNELS_2C:\n",
    "    fname += str(c)\n",
    "fname += \"_k\"\n",
    "for k in KERNEL_SIZE:\n",
    "    fname += str(k)\n",
    "fname += \"_lr\" + str(LEARNING_RATE)\n",
    "fname += \"_m\" + str(MOMENTUM)\n",
    "fname += \"_g\" + str(GAMMA)\n",
    "fname += \"_d\" + str(DROPOUT)\n",
    "\n",
    "print(\"Model name: \", fname)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ccb6a56d1d57dfe3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from datetime import datetime\n",
    "\n",
    "from src.training.cnn import LitEuroSatCnn\n",
    "\n",
    "lightning_model = LitEuroSatCnn(\n",
    "    num_classes=NUM_CLASSES,\n",
    "    learning_rate=LEARNING_RATE, \n",
    "    num_channels=len(CHANNELS_2C), \n",
    "    kernel_size=KERNEL_SIZE,\n",
    "    momentum=MOMENTUM,\n",
    "    gamma=GAMMA,\n",
    "    weights=torch.tensor(w, dtype=torch.float32),\n",
    "    dropout=DROPOUT\n",
    ")\n",
    "\n",
    "logger = WandbLogger(\n",
    "    project=\"eurosat_cnn\",\n",
    "    name=\"cnn_v1\",\n",
    "    log_model=False,\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=CKPT_PATH + datetime.now().strftime(\"%H-%M\"),\n",
    "    filename=fname + '_{epoch:02d}-{val_loss:.2f}',\n",
    "    save_top_k=2, \n",
    "    monitor=\"val_loss\",\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=EPOCHS,\n",
    "    accelerator=\"gpu\", \n",
    "    devices=1,\n",
    "    logger=logger,\n",
    "    callbacks=[checkpoint_callback],\n",
    ")\n",
    "\n",
    "trainer.fit(lightning_model, datamodule=data_module)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa70fc0415fe6817",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "trainer.test(lightning_model, datamodule=data_module, ckpt_path=checkpoint_callback.best_model_path)\n",
    "metric = torchmetrics.ConfusionMatrix(task=\"multiclass\", num_classes=NUM_CLASSES)\n",
    "all_preds = np.concatenate(lightning_model.ep_out)\n",
    "all_true = np.concatenate(lightning_model.ep_true)\n",
    "true_ep = torch.tensor(all_true)\n",
    "pred_ep = torch.tensor(all_preds)\n",
    "metric.update(pred_ep, true_ep)\n",
    "fig, ax = metric.plot()\n",
    "plt.show()\n",
    "print(encoder.categories_[0])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2bb7804baa9a7fa0",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2e31138fe1fbd612"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pretrained Model Training\n",
    "### Training Phase 1\n",
    "##### Pretrained ResNet50, ResNet18, AlexNet, ViT Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7460c66721ff7c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EuroSatPreTrainedModel(\n",
      "  (backbone): VisionTransformer(\n",
      "    (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
      "    (encoder): Encoder(\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (layers): Sequential(\n",
      "        (encoder_layer_0): EncoderBlock(\n",
      "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (self_attention): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): MLPBlock(\n",
      "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (1): GELU(approximate='none')\n",
      "            (2): Dropout(p=0.0, inplace=False)\n",
      "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (4): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (encoder_layer_1): EncoderBlock(\n",
      "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (self_attention): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): MLPBlock(\n",
      "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (1): GELU(approximate='none')\n",
      "            (2): Dropout(p=0.0, inplace=False)\n",
      "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (4): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (encoder_layer_2): EncoderBlock(\n",
      "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (self_attention): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): MLPBlock(\n",
      "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (1): GELU(approximate='none')\n",
      "            (2): Dropout(p=0.0, inplace=False)\n",
      "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (4): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (encoder_layer_3): EncoderBlock(\n",
      "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (self_attention): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): MLPBlock(\n",
      "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (1): GELU(approximate='none')\n",
      "            (2): Dropout(p=0.0, inplace=False)\n",
      "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (4): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (encoder_layer_4): EncoderBlock(\n",
      "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (self_attention): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): MLPBlock(\n",
      "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (1): GELU(approximate='none')\n",
      "            (2): Dropout(p=0.0, inplace=False)\n",
      "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (4): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (encoder_layer_5): EncoderBlock(\n",
      "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (self_attention): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): MLPBlock(\n",
      "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (1): GELU(approximate='none')\n",
      "            (2): Dropout(p=0.0, inplace=False)\n",
      "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (4): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (encoder_layer_6): EncoderBlock(\n",
      "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (self_attention): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): MLPBlock(\n",
      "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (1): GELU(approximate='none')\n",
      "            (2): Dropout(p=0.0, inplace=False)\n",
      "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (4): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (encoder_layer_7): EncoderBlock(\n",
      "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (self_attention): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): MLPBlock(\n",
      "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (1): GELU(approximate='none')\n",
      "            (2): Dropout(p=0.0, inplace=False)\n",
      "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (4): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (encoder_layer_8): EncoderBlock(\n",
      "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (self_attention): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): MLPBlock(\n",
      "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (1): GELU(approximate='none')\n",
      "            (2): Dropout(p=0.0, inplace=False)\n",
      "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (4): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (encoder_layer_9): EncoderBlock(\n",
      "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (self_attention): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): MLPBlock(\n",
      "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (1): GELU(approximate='none')\n",
      "            (2): Dropout(p=0.0, inplace=False)\n",
      "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (4): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (encoder_layer_10): EncoderBlock(\n",
      "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (self_attention): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): MLPBlock(\n",
      "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (1): GELU(approximate='none')\n",
      "            (2): Dropout(p=0.0, inplace=False)\n",
      "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (4): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (encoder_layer_11): EncoderBlock(\n",
      "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (self_attention): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): MLPBlock(\n",
      "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (1): GELU(approximate='none')\n",
      "            (2): Dropout(p=0.0, inplace=False)\n",
      "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (4): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    )\n",
      "    (heads): Identity()\n",
      "  )\n",
      "  (criterion): CrossEntropyLoss()\n",
      "  (classifier): Sequential(\n",
      "    (fc_0): Linear(in_features=768, out_features=256, bias=True)\n",
      "    (relu_0): ReLU()\n",
      "    (dropout_0): Dropout(p=0.3, inplace=False)\n",
      "    (fc_out): Linear(in_features=256, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tabulate import tabulate\n",
    "from src.training.pretrainedModels import get_pretrained_model\n",
    "from src.training.data import EuroSatDataModule\n",
    "from src.training.pretrainedModels import EuroSatPreTrainedModel\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "CKPT_PATH = f'checkpoints/{PRETRAINED_MODEL}/'\n",
    "\n",
    "model, _ = get_pretrained_model(PRETRAINED_MODEL)\n",
    "\n",
    "data_module = EuroSatDataModule(ds_train, ds_val, ds_test, BATCH_SIZE)\n",
    "\n",
    "model_train = EuroSatPreTrainedModel(\n",
    "    backbone=model,\n",
    "    learning_rate=0.0005,\n",
    "    layers=[256],\n",
    "    opt=\"sgd\",\n",
    "    gamma=0.9,\n",
    "    momentum=0.9,\n",
    "    dropout=0.3,\n",
    "    weight_decay=0.001\n",
    ")\n",
    "print(model_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T13:17:40.338765Z",
     "start_time": "2024-03-30T13:17:39.122148Z"
    }
   },
   "id": "42a5f7c4ad819ffe",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mthe-virus\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "wandb version 0.16.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.16.4"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>./wandb/run-20240330_141744-yad7bhqg</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/the-virus/eurosat_vit/runs/yad7bhqg' target=\"_blank\">vit_b_16</a></strong> to <a href='https://wandb.ai/the-virus/eurosat_vit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/the-virus/eurosat_vit' target=\"_blank\">https://wandb.ai/the-virus/eurosat_vit</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/the-virus/eurosat_vit/runs/yad7bhqg' target=\"_blank\">https://wandb.ai/the-virus/eurosat_vit/runs/yad7bhqg</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type              | Params\n",
      "-------------------------------------------------\n",
      "0 | backbone   | VisionTransformer | 85.8 M\n",
      "1 | criterion  | CrossEntropyLoss  | 0     \n",
      "2 | classifier | Sequential        | 199 K \n",
      "-------------------------------------------------\n",
      "199 K     Trainable params\n",
      "85.8 M    Non-trainable params\n",
      "86.0 M    Total params\n",
      "343.992   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4dd9c652e529489c8ff111086e8ea482"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a1260b16a8274cbd8fd5daf65256f23e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d2735689a08347418888886d4ed181ff"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2345b9381f914774a9c3c0b87a8bb045"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "85ecf2afc1c8494e92abbd130c7b193b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "494ac3c06b954f6d88fbbf4b29cfafd0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "14887008c07b4e70b806b6298d5b983e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "logger = WandbLogger(\n",
    "    project=\"eurosat_\" + PRETRAINED_MODEL.split(\"_\")[0],\n",
    "    name=PRETRAINED_MODEL,\n",
    "    log_model=False,\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=CKPT_PATH + datetime.now().strftime(\"%H-%M\"),\n",
    "    filename='{epoch:02d}-{val_loss:.2f}-{train_loss_epoch:.2f}',\n",
    "    save_top_k=5, \n",
    "    monitor=\"val_loss\",\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=5,\n",
    "    accelerator=\"gpu\", \n",
    "    devices=1,\n",
    "    logger=logger,\n",
    "    callbacks=[checkpoint_callback],\n",
    ")\n",
    "\n",
    "trainer.fit(model_train, datamodule=data_module)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T13:35:09.173330Z",
     "start_time": "2024-03-30T13:17:42.426862Z"
    }
   },
   "id": "efb3d4dce1d9c8f8",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "from datetime import datetime\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "logger = WandbLogger(\n",
    "    project=\"eurosat_\" + PRETRAINED_MODEL.split(\"_\")[0],\n",
    "    name=PRETRAINED_MODEL,\n",
    "    log_model=False,\n",
    ")\n",
    "model, _ = get_pretrained_model(PRETRAINED_MODEL)\n",
    "\n",
    "model_eval = EuroSatPreTrainedModel.load_from_checkpoint(\n",
    "    \"checkpoints/resnet50_RGB_MOCO/12-15/epoch=02-val_loss=1.73.ckpt\", #checkpoint_callback.best_model_path,\n",
    "    backbone=model,\n",
    "    learning_rate=0.001,\n",
    "    layers=[],\n",
    "    gamma=0.95,\n",
    "    momentum=0.9,\n",
    "    dropout=0.3,\n",
    "    weight_decay=1e-5\n",
    ")\n",
    "\n",
    "for param in model_eval.backbone.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# for param in model_eval.backbone.layer3[-3:].parameters():\n",
    "#     param.requires_grad = True\n",
    "\n",
    "for param in model_eval.backbone.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "tabel = []\n",
    "for name, param in model_eval.backbone.named_parameters():\n",
    "    num_params = f\"{param.numel() // 1000}k\"\n",
    "    tabel.append([f\"{c.OKGREEN}{name}{c.ENDC}\", f\"{c.OKBLUE}{param.requires_grad}{c.ENDC}\", num_params])\n",
    "\n",
    "print(tabulate(tabel, headers=[f\"{c.OKGREEN}Layer{c.ENDC}\", f\"{c.OKBLUE}Trainable{c.ENDC}\", f\"Parameters\"]))\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=CKPT_PATH + datetime.now().strftime(\"%H-%M\"),\n",
    "    filename='{epoch:02d}-{val_loss:.2f}',\n",
    "    save_top_k=4, \n",
    "    monitor=\"val_loss\",\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=10,\n",
    "    accelerator=\"gpu\", \n",
    "    devices=1,\n",
    "    logger=logger,\n",
    "    callbacks=[checkpoint_callback],\n",
    ")\n",
    "\n",
    "trainer.fit(model_eval, datamodule=data_module)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f2257a269c6160b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "trainer.validate(model_train, datamodule=data_module, ckpt_path=\"checkpoints/vit_b_16/13-19/epoch=03-val_loss=1.44-train_loss_epoch=0.47.ckpt\")#checkpoint_callback.best_model_path)\n",
    "\n",
    "all_preds = np.concatenate(model_train.ep_out)\n",
    "all_true = np.concatenate(model_train.ep_true)\n",
    "true_ep = torch.tensor(all_true)\n",
    "pred_ep = torch.tensor(all_preds)\n",
    "\n",
    "metric = torchmetrics.ConfusionMatrix(task=\"multiclass\", num_classes=NUM_CLASSES)\n",
    "metric.update(pred_ep, true_ep)\n",
    "confmat = metric.compute()\n",
    "confmat_np = confmat.numpy()\n",
    "tick_labels = [encoder.categories_[0][i] for i in range(NUM_CLASSES)]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(confmat_np, annot=True, fmt='g', cmap='Blues', \n",
    "            xticklabels=tick_labels, yticklabels=tick_labels)\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a744160ec48183d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "from src.training.pretrainedModels import EuroSatPreTrainedModel\n",
    "from datetime import datetime\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import BackboneFinetuning, ModelCheckpoint\n",
    "from pytorch_lightning import Trainer\n",
    "from src.training.data import EuroSatDataModule\n",
    "import random\n",
    "import torch\n",
    "import gc\n",
    "import wandb\n",
    "\n",
    "CKPT_PATH = f'checkpoints/{PRETRAINED_MODEL}/'\n",
    "\n",
    "n_rounds = 20\n",
    "gamma = 0.95\n",
    "momentum = 0.9\n",
    "dropout = 0.3\n",
    "\n",
    "layers_samples = [[], [256]]\n",
    "\n",
    "wdec = [0.01, 0.001, 0.0001]\n",
    "\n",
    "optims = [\"adam\", \"sgd\"]\n",
    "\n",
    "lr_samples = [0.01, 0.001, 0.0005, 0.0001]\n",
    "\n",
    "bs_samples = [128]\n",
    "\n",
    "param_space = [[l, b, wd, ly, opt] for l in lr_samples for b in bs_samples for wd in wdec for ly in layers_samples for opt in optims]\n",
    "random.shuffle(param_space)\n",
    "\n",
    "out_table = []\n",
    "\n",
    "for i in range(n_rounds):\n",
    "    lr_hp, bs_hp, wd, ly, opt = param_space[i]\n",
    "    \n",
    "    print(f\"{c.OKBLUE}Round {i+1}/{n_rounds}{c.ENDC}\")\n",
    "    print(f\"{c.OKBLUE}Learning Rate: {lr_hp:.4f}, Batch Size: {bs_hp}, Weight Decay: {wd}, Layers: {ly}, Optimizer: {opt}{c.ENDC}\")\n",
    "    \n",
    "    data_module = EuroSatDataModule(ds_train, ds_val, ds_test, bs_hp)\n",
    "    \n",
    "    model, _ = get_pretrained_model(PRETRAINED_MODEL)\n",
    "    model_train = EuroSatPreTrainedModel(\n",
    "        backbone=model,\n",
    "        layers=ly,\n",
    "        opt=opt,\n",
    "        learning_rate=lr_hp,\n",
    "        gamma=gamma,\n",
    "        momentum=momentum,\n",
    "        dropout=dropout,\n",
    "        weight_decay=wd\n",
    "    )\n",
    "    \n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=CKPT_PATH + \"hp_tuning\" + f\"/round_{i}\",\n",
    "        filename=f\"bs_{bs_hp}_lr_{lr_hp}_wd_{wd}_loss_\" + '{val_loss:.2f}',\n",
    "        save_top_k=1, \n",
    "        monitor=\"val_loss\",\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    wandb_logger = WandbLogger(\n",
    "        project=\"eurosat_resnet\",\n",
    "        name=f\"bs_{bs_hp}_lr_{round(lr_hp, 4)}_wd_{wd}\",\n",
    "        log_model=False,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        max_epochs=2,\n",
    "        accelerator=\"gpu\", \n",
    "        devices=1,\n",
    "        logger=wandb_logger,\n",
    "        callbacks=[checkpoint_callback],\n",
    "    )\n",
    "\n",
    "    trainer.fit(model_train, datamodule=data_module)\n",
    "    trainer.validate(model_train, datamodule=data_module, ckpt_path=checkpoint_callback.best_model_path, verbose=False)\n",
    "    score = model_train.accuracy\n",
    "    out_table.append([lr_hp, bs_hp, wd, ly, opt, score])\n",
    "    print(tabulate(out_table, headers=[\"Learning Rate\", \"Batch Size\", \"Weight Decay\", \"Layers\", \"Optimizer\", \"Accuracy\"]))\n",
    "    wandb.finish()\n",
    "    data_module = None\n",
    "    model_train = None\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "print(tabulate(out_table, headers=[\"Learning Rate\", \"Batch Size\", \"Weight Decay\", \"Layers\", \"Optimizer\", \"Accuracy\"]))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28a7c062d1e82c9e",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Predict on the test set"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d14c14d786b83fa8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from src.datasets.EuroSatTest import EuroSatTestSet\n",
    "from torch.utils.data import DataLoader\n",
    "from config import Config\n",
    "from src.training.pretrainedModels import get_pretrained_model\n",
    "\n",
    "config = Config()\n",
    "\n",
    "_, transform = get_pretrained_model(PRETRAINED_MODEL)\n",
    "\n",
    "mean_std_S2A = {\n",
    "    'mean': [1307.6, 1151.7, 889.6],\n",
    "    'std': [1375.2, 1188.1, 1159.1]\n",
    "}\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     K.CenterCrop(size=(56, 56)),\n",
    "#     K.RandomHorizontalFlip(),\n",
    "# ])\n",
    "\n",
    "dataset = EuroSatTestSet(config.TEST_MS_DIR, select_chan=CHANNELS_2A, add_B10=False, mean_std=mean_std_S2A, transform=transform) #, augment=augmentation)\n",
    "dataloader = DataLoader(dataset, batch_size=256, shuffle=False)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fbe57812c3ba259",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from src.training.pretrainedModels import EuroSatPreTrainedModel\n",
    "from src.training.cnn import LitEuroSatCnn\n",
    "from config import Config\n",
    "from src.training.pretrainedModels import get_pretrained_model\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "config = Config()\n",
    "\n",
    "# model_eval = LitEuroSatCnn.load_from_checkpoint(\n",
    "#     \"checkpoints/cnn/14-18/cnn_c87654_k53_lr0.03_m0.9_g0.8epoch=09-val_loss=0.68.ckpt\", #checkpoint_callback.best_model_path,\n",
    "#     num_classes=NUM_CLASSES,\n",
    "#     learning_rate=0.025, \n",
    "#     num_channels=len(CHANNELS), \n",
    "#     kernel_size=[5, 3],\n",
    "#     momentum=0.9,\n",
    "#     gamma=0.9,\n",
    "#     weights=torch.tensor(w, dtype=torch.float32)\n",
    "# )\n",
    "model, _ = get_pretrained_model(PRETRAINED_MODEL)\n",
    "model_eval = EuroSatPreTrainedModel.load_from_checkpoint(\n",
    "    \"checkpoints/resnet50_RGB/12-57/epoch=04-val_loss=1.52-train_loss_epoch=0.86.ckpt\", #checkpoint_callback.best_model_path,\n",
    "    backbone=model,\n",
    "    learning_rate=1e-4,\n",
    "    layers=[],\n",
    "    momentum=0.9,\n",
    "    dropout=0,\n",
    "    weight_decay=0.0001\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=4,\n",
    "    accelerator=\"gpu\", \n",
    "    devices=1,\n",
    "    logger=None,\n",
    "    callbacks=[],\n",
    ")\n",
    "\n",
    "trainer.test(model_eval, datamodule=data_module)\n",
    "\n",
    "model_eval.eval()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b042a06f7a52870c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_eval = model_eval.to(device)\n",
    "model_eval.eval()\n",
    "\n",
    "N_CLASSES = 10\n",
    "categorys = dataset.enc.categories_[0]\n",
    "print(categorys)\n",
    "\n",
    "predictions = []\n",
    "probabilities = []\n",
    "ohe = []\n",
    "images = []\n",
    "sample_ids = []\n",
    "\n",
    "    \n",
    "with torch.no_grad():\n",
    "    for batch in dataloader:\n",
    "        inputs, samp_id = batch\n",
    "        inputs = inputs.to(device)\n",
    "            \n",
    "        outputs = model_eval(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        preds = np.array(preds.cpu().numpy())\n",
    "        \n",
    "        pred_labels = np.array([categorys[p] for p in preds])\n",
    "        \n",
    "        predictions.extend(pred_labels)\n",
    "        images.extend(inputs.cpu())\n",
    "        sample_ids.extend(samp_id.cpu())\n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "194979db7753d23d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sub_df = pd.DataFrame({'test_id': np.array(sample_ids), 'label': np.array(predictions)})\n",
    "sub_df = sub_df.sort_values(by='test_id')\n",
    "print(sub_df.head())\n",
    "print(np.array(sample_ids))\n",
    "\n",
    "sub_df.to_csv('submission.csv', index=False)\n",
    "print(np.unique(predictions, return_counts=True))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "58b692ad612e50fa",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.nn.functional import interpolate\n",
    "\n",
    "# [ 606,  550,  229,  628,  216,  182,  280,  447,   89, 1005]\n",
    "# [ 876,  601,  219,  582,  195,   55,  164,  458,   63, 1019]\n",
    "def overlay_cam_on_image(im, cam_mask):\n",
    "    cam_mask = (cam_mask - cam_mask.min()) / (cam_mask.max() - cam_mask.min())\n",
    "    print(cam_mask.shape)\n",
    "\n",
    "    print(im.shape)\n",
    "    # Resize the CAM mask to match the image size\n",
    "    cam_mask = interpolate(cam_mask, size=im.shape, mode='nearest').squeeze(0)\n",
    "    print(im.shape)\n",
    "    print(cam_mask.shape)\n",
    "    # Convert CAM mask to heatmap\n",
    "    heatmap = plt.get_cmap('jet')(cam_mask.cpu().detach().numpy())[:, :, :3]  # Get the RGB part, discard alpha\n",
    "    heatmap = torch.from_numpy(heatmap).permute(2, 0, 1).float()\n",
    "\n",
    "    # Overlay the heatmap on the image\n",
    "    combined_img = heatmap * 0.3 + im.cpu() * 0.5  # Adjust opacity as needed\n",
    "\n",
    "    return combined_img"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af1903acbac15b5a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from pytorch_grad_cam import GradCAM\n",
    "\n",
    "import torch\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "grad_cam_c = False\n",
    "samp_batch_idx = [i for i in range(0, len(sample_ids))]\n",
    "random.shuffle(samp_batch_idx)\n",
    "samp_batch_idx = np.array(samp_batch_idx)\n",
    "n = 10\n",
    "\n",
    "for param in model_eval.backbone.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "\n",
    "# target_layer = [model_eval.backbone.layer4[-1].conv1]\n",
    "\n",
    "\n",
    "for batch_start in range(0, n*8, 8):  # Iterate in steps of 8\n",
    "    fig, axs = plt.subplots(2, 4, figsize=(20, 10))  # Create a new figure for each batch\n",
    "    axs = axs.flatten()  # Flatten the grid for easy iteration\n",
    "\n",
    "    for idx, ax in zip(samp_batch_idx[batch_start:batch_start+8], axs):\n",
    "        pred = predictions[idx]\n",
    "        samp_id = sample_ids[idx]\n",
    "        im_path = config.DATA_DIR + f\"test/NoLabel/test_{samp_id}.npy\"\n",
    "        # img = images[idx].unsqueeze(0).requires_grad_(True).to(device)\n",
    "        img = np.load(im_path).transpose(2, 0, 1)\n",
    "        img = img[[3, 2, 1]].astype(np.float32)\n",
    "        \n",
    "        rgb_min, rgb_max = img.min(), img.max()\n",
    "        img = (img - rgb_min) / (rgb_max - rgb_min)\n",
    "        img = img.clip(0, 1)\n",
    "        \n",
    "        \n",
    "        if grad_cam_c:\n",
    "            pass\n",
    "            # img = images[idx].unsqueeze(0).requires_grad_(True).to(device)\n",
    "            # cam = GradCAM(model=model_eval, target_layers=target_layer)\n",
    "            # grayscale_cam = cam(input_tensor=img, targets=None)\n",
    "            # cam_mask_tensor = torch.tensor(grayscale_cam).unsqueeze(0)\n",
    "            # ax.imshow(cam_mask_tensor.squeeze(0).squeeze(0).cpu().numpy(), cmap='jet', alpha=0.1)\n",
    "        else:\n",
    "            ax.imshow(img.transpose(1, 2, 0))\n",
    "        ax.set_title(pred, fontsize=20)\n",
    "        ax.axis('off')\n",
    "        \n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(wspace=0.2, hspace=0.2)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e11bec6bf308538",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "281c961934319e86"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
