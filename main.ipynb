{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Load the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c96e1dbdb152f98"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:44:45.360041Z",
     "start_time": "2024-03-21T16:44:45.355199Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.colors import bcolors\n",
    "from config import Config\n",
    "\n",
    "c = bcolors()\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import kornia.augmentation as K\n",
    "import torch\n",
    "from src.pickle_loader import load_object, save_object\n",
    "\n",
    "stats = load_object(\"../data/eurosat_ms_mean_std\")\n",
    "mean = stats['mean']\n",
    "std = stats['std']\n",
    "chan_idx = stats['idx']\n",
    "\n",
    "# CHANNELS = [12, 11, 8, 7]\n",
    "CHANNELS = [3, 2, 1]\n",
    "NUM_CLASSES = 10\n",
    "NUM_AUG = 1\n",
    "\n",
    "df = pd.read_csv(config.TRAIN_FILE)\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "encoder = encoder.fit(df[['label']].values.reshape(-1, 1))\n",
    "save_object(encoder, \"../data/on_hot_encoder\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:44:48.565302Z",
     "start_time": "2024-03-21T16:44:45.809868Z"
    }
   },
   "id": "ea2db869e77d2168",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AnnualCrop' 'Forest' 'HerbaceousVegetation' 'Highway' 'Industrial'\n",
      " 'Pasture' 'PermanentCrop' 'Residential' 'River' 'SeaLake']\n",
      "\n",
      "\u001B[92mPreloading images...\u001B[0m\n",
      "\n",
      "\u001B[96mImages:         21600\u001B[0m\n",
      "\u001B[96mAugmentations:  21600\u001B[0m\n",
      "\u001B[96mJobs:           -4 \u001B[0m\n",
      "\n",
      "\u001B[94mTime taken:      0 min 30.285677433013916 sec \u001B[0m\n",
      "\n",
      "\u001B[92mPreloading images...\u001B[0m\n",
      "\n",
      "\u001B[96mImages:         3780\u001B[0m\n",
      "\u001B[96mAugmentations:  3780\u001B[0m\n",
      "\u001B[96mJobs:           -4 \u001B[0m\n",
      "\n",
      "\u001B[94mTime taken:      0 min 2.0486361980438232 sec \u001B[0m\n",
      "\n",
      "\u001B[92mPreloading images...\u001B[0m\n",
      "\n",
      "\u001B[96mImages:         1620\u001B[0m\n",
      "\u001B[96mAugmentations:  1620\u001B[0m\n",
      "\u001B[96mJobs:           -4 \u001B[0m\n",
      "\n",
      "\u001B[94mTime taken:      0 min 0.9670822620391846 sec \u001B[0m\n",
      "\n",
      "\u001B[96mTrain dataset:   21600 samples\u001B[0m\n",
      "\u001B[96mValidation dataset: 3780 samples\u001B[0m\n",
      "\u001B[96mTest dataset:       1620 samples\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from src.datasets.EuroSatMS import EuroSatMS\n",
    "\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['label'])\n",
    "print(df['label'].unique())\n",
    "test_df, val_df = train_test_split(val_df, test_size=0.7)\n",
    "\n",
    "ds_train = EuroSatMS(\n",
    "    train_df, \n",
    "    config.TRAIN_MS_DIR,\n",
    "    encoder=encoder,\n",
    "    num_aug=NUM_AUG, \n",
    "    select_chan=CHANNELS\n",
    ")\n",
    "\n",
    "ds_val = EuroSatMS(\n",
    "    val_df, \n",
    "    config.TRAIN_MS_DIR,\n",
    "    encoder=encoder,\n",
    "    num_aug=NUM_AUG, \n",
    "    select_chan=CHANNELS\n",
    ")\n",
    "\n",
    "ds_test = EuroSatMS(\n",
    "    test_df, \n",
    "    config.TRAIN_MS_DIR,\n",
    "    encoder=encoder,\n",
    "    num_aug=NUM_AUG, \n",
    "    select_chan=CHANNELS\n",
    ")\n",
    "\n",
    "print(f\"\"\"\\n{c.OKCYAN}Train dataset:   {len(ds_train)} samples{c.ENDC}\"\"\")\n",
    "print(f\"\"\"{c.OKCYAN}Validation dataset: {len(ds_val)} samples{c.ENDC}\"\"\")\n",
    "print(f\"\"\"{c.OKCYAN}Test dataset:       {len(ds_test)} samples{c.ENDC}\"\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:45:22.150670Z",
     "start_time": "2024-03-21T16:44:48.690104Z"
    }
   },
   "id": "89850dd26de91e3a",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "transform_mean_std = transforms.Compose([\n",
    "    K.Normalize(mean=mean[CHANNELS], std=std[CHANNELS])\n",
    "])\n",
    "\n",
    "transform_pt = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "p1 = 0.5\n",
    "p2 = 0.6\n",
    "p3 = 0.6\n",
    "augmentation = nn.Sequential(\n",
    "    K.RandomHorizontalFlip(p=p3),\n",
    "    K.RandomVerticalFlip(p=p3),\n",
    "    K.RandomAffine(degrees=45, translate=None, scale=None, shear=None, resample=\"nearest\", padding_mode=2, p=p2),\n",
    "    K.RandomShear(shear=0.3, resample=\"nearest\", padding_mode=2, p=p2),\n",
    "    K.RandomContrast(contrast=(0.8, 1.2), p=p1),\n",
    "    K.RandomBrightness((0.7, 1.3), p=p2),\n",
    "    # K.RandomPlasmaContrast(roughness=(0.1, 0.4), p=p1),\n",
    "    # K.RandomSolarize(thresholds=0.1, p=p1),\n",
    "    K.RandomSaturation((0.9, 1.1), p=p1),\n",
    "    # K.RandomBoxBlur(kernel_size=(3, 3), p=p1),\n",
    "    #K.RandomEqualize(p=p1),\n",
    "    K.CenterCrop(size=(64, 64))\n",
    ")\n",
    "\n",
    "ds_train.augment = augmentation\n",
    "ds_val.augment = None\n",
    "ds_test.augment = None\n",
    "\n",
    "ds_train.transform = None\n",
    "ds_val.transform = None\n",
    "ds_test.transform = None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:45:22.169781Z",
     "start_time": "2024-03-21T16:45:22.153279Z"
    }
   },
   "id": "a5e5a55b27ee41b1",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CNN Model Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "693660b793045e2a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from src.training.data import EuroSatDataModule\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "data_module = EuroSatDataModule(ds_train, ds_val, ds_test, BATCH_SIZE)\n",
    "print(f\"\"\"{c.OKGREEN}Initialized the data module...{c.ENDC}\"\"\")\n",
    "\n",
    "KERNEL_SIZE = [5, 3]\n",
    "LEARNING_RATE = 0.03\n",
    "MOMENTUM = 0.9\n",
    "GAMMA = 0.9\n",
    "DROPOUT = 0.3\n",
    "EPOCHS = 15\n",
    "CKPT_PATH = 'checkpoints/cnn/'\n",
    "CLASS_WEIGHTS = {'AnnualCrop': 9,\n",
    "                 'Forest': 9,\n",
    "                 'HerbaceousVegetation': 8, \n",
    "                 'Highway': 9, \n",
    "                 'Industrial': 9,\n",
    "                 'Pasture': 9, \n",
    "                 'PermanentCrop': 9, \n",
    "                 'Residential': 9, \n",
    "                 'River': 9, \n",
    "                 'SeaLake': 9}\n",
    "\n",
    "w = np.array(list(CLASS_WEIGHTS.values()))\n",
    "w_min, w_max = w.min(), w.max()\n",
    "w = (w - w_min) / (w_max - w_min)\n",
    "\n",
    "fname = \"cnn_c\"\n",
    "for c in CHANNELS:\n",
    "    fname += str(c)\n",
    "fname += \"_k\"\n",
    "for k in KERNEL_SIZE:\n",
    "    fname += str(k)\n",
    "fname += \"_lr\" + str(LEARNING_RATE)\n",
    "fname += \"_m\" + str(MOMENTUM)\n",
    "fname += \"_g\" + str(GAMMA)\n",
    "fname += \"_d\" + str(DROPOUT)\n",
    "\n",
    "print(\"Model name: \", fname)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ccb6a56d1d57dfe3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import BackboneFinetuning, ModelCheckpoint\n",
    "from src.training.cnn import LitEuroSatCnn\n",
    "from datetime import datetime\n",
    "\n",
    "lightning_model = LitEuroSatCnn(\n",
    "    num_classes=NUM_CLASSES,\n",
    "    learning_rate=LEARNING_RATE, \n",
    "    num_channels=len(CHANNELS), \n",
    "    kernel_size=KERNEL_SIZE,\n",
    "    momentum=MOMENTUM,\n",
    "    gamma=GAMMA,\n",
    "    weights=torch.tensor(w, dtype=torch.float32),\n",
    "    dropout=DROPOUT\n",
    ")\n",
    "\n",
    "logger = WandbLogger(\n",
    "    project=\"eurosat_cnn\",\n",
    "    name=\"cnn_v1\",\n",
    "    log_model=False,\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=CKPT_PATH + datetime.now().strftime(\"%H-%M\"),\n",
    "    filename=fname + '_{epoch:02d}-{val_loss:.2f}',\n",
    "    save_top_k=2, \n",
    "    monitor=\"val_loss\",\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=EPOCHS,\n",
    "    accelerator=\"gpu\", \n",
    "    devices=1,\n",
    "    logger=logger,\n",
    "    callbacks=[checkpoint_callback],\n",
    ")\n",
    "\n",
    "trainer.fit(lightning_model, datamodule=data_module)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa70fc0415fe6817",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "trainer.test(lightning_model, datamodule=data_module, ckpt_path=checkpoint_callback.best_model_path)\n",
    "metric = torchmetrics.ConfusionMatrix(task=\"multiclass\", num_classes=NUM_CLASSES)\n",
    "all_preds = np.concatenate(lightning_model.ep_out)\n",
    "all_true = np.concatenate(lightning_model.ep_true)\n",
    "true_ep = torch.tensor(all_true)\n",
    "pred_ep = torch.tensor(all_preds)\n",
    "metric.update(pred_ep, true_ep)\n",
    "fig, ax = metric.plot()\n",
    "plt.show()\n",
    "print(encoder.categories_[0])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2bb7804baa9a7fa0",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2e31138fe1fbd612"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pretrained Model Training\n",
    "### Training Phase 1\n",
    "##### Pretrained ResNet50, ResNet18, AlexNet Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7460c6672b1ff7c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToTensor, Compose, Normalize, Resize\n",
    "from transformers import ViTImageProcessor, ViTForImageClassification\n",
    "import torchgeo.models as models\n",
    "from torchgeo.models import ResNet18_Weights, ResNet50_Weights\n",
    "\n",
    "\n",
    "def get_pretrained_model(model_name):\n",
    "    if model_name == \"B13_rn50_moco_0099\":\n",
    "        m = models.resnet50(weights=None)\n",
    "        m.fc = nn.Linear(2048,19)\n",
    "        m.conv1 = nn.Conv2d(\n",
    "            13, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
    "        )\n",
    "        ckp = torch.load(\"B13_rn50_moco_0099.pth\", map_location=\"cpu\")\n",
    "        sd = ckp['state_dict']\n",
    "        \n",
    "        for key in list(sd.keys()):\n",
    "            if key.startswith('module.encoder_q') and not key.startswith('module.encoder_q.fc'):\n",
    "                sd[key[len(\"module.encoder_q.\"):]] = sd[key]\n",
    "            del sd[key]\n",
    "        \n",
    "        msg = m.load_state_dict(sd, strict=False)\n",
    "        assert set(msg.missing_keys) == {\"fc.weight\", \"fc.bias\"}\n",
    "        \n",
    "        return m\n",
    "    elif \"resnet18_RGB_MOCO\" in model_name:\n",
    "        return models.resnet18(weights=ResNet18_Weights.SENTINEL2_RGB_MOCO)\n",
    "    elif \"resnet50_RGB_MOCO\" in model_name:\n",
    "        return models.resnet50(weights=ResNet50_Weights.SENTINEL2_RGB_MOCO)\n",
    "    elif \"resnet50_MS_SECO\" in model_name:\n",
    "        return models.resnet50(weights=ResNet50_Weights.SENTINEL2_RGB_SECO)\n",
    "    elif \"ViT\" in model_name:\n",
    "        model_name = \"google/vit-base-patch16-224\"\n",
    "        processor = ViTImageProcessor.from_pretrained(model_name) \n",
    "        \n",
    "        mu, sigma = processor.image_mean, processor.image_std\n",
    "        size = processor.size\n",
    "        norm = Normalize(mean=mu, std=sigma)\n",
    "        \n",
    "        tr = Compose([\n",
    "            Resize(size['height']),\n",
    "            ToTensor(),\n",
    "            norm\n",
    "        ])\n",
    "        \n",
    "        ds_train.transform = tr\n",
    "        ds_val.transform = tr\n",
    "        ds_test.transform = tr\n",
    "        \n",
    "        model_name = \"google/vit-base-patch16-224\"\n",
    "        return ViTForImageClassification.from_pretrained(model_name)\n",
    "\n",
    "m_name = \"ViT\"\n",
    "CKPT_PATH = f'checkpoints/{m_name}/'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:45:24.042734Z",
     "start_time": "2024-03-21T16:45:22.171607Z"
    }
   },
   "id": "a7506054d07ddabd",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92mInitialized the data module...\u001B[0m\n",
      "ViTForImageClassification(\n",
      "  (vit): ViTModel(\n",
      "    (embeddings): ViTEmbeddings(\n",
      "      (patch_embeddings): ViTPatchEmbeddings(\n",
      "        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
      "      )\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (encoder): ViTEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x ViTLayer(\n",
      "          (attention): ViTAttention(\n",
      "            (attention): ViTSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (output): ViTSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ViTIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ViTOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  )\n",
      "  (classifier): Linear(in_features=768, out_features=1000, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mthe-virus\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.16.4"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>./wandb/run-20240321_174628-dqsv2kay</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/the-virus/eurosat_resnet/runs/dqsv2kay' target=\"_blank\">ViT</a></strong> to <a href='https://wandb.ai/the-virus/eurosat_resnet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/the-virus/eurosat_resnet' target=\"_blank\">https://wandb.ai/the-virus/eurosat_resnet</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/the-virus/eurosat_resnet/runs/dqsv2kay' target=\"_blank\">https://wandb.ai/the-virus/eurosat_resnet/runs/dqsv2kay</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type                      | Params\n",
      "---------------------------------------------------------\n",
      "0 | backbone   | ViTForImageClassification | 86.6 M\n",
      "1 | classifier | Linear                    | 10.0 K\n",
      "2 | criterion  | CrossEntropyLoss          | 0     \n",
      "---------------------------------------------------------\n",
      "10.0 K    Trainable params\n",
      "86.6 M    Non-trainable params\n",
      "86.6 M    Total params\n",
      "346.311   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eff9db7e4f8441c885736ab572e9a3bd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "linear(): argument 'input' (position 1) must be Tensor, not ImageClassifierOutput",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 47\u001B[0m\n\u001B[1;32m     31\u001B[0m checkpoint_callback \u001B[38;5;241m=\u001B[39m ModelCheckpoint(\n\u001B[1;32m     32\u001B[0m     dirpath\u001B[38;5;241m=\u001B[39mCKPT_PATH \u001B[38;5;241m+\u001B[39m datetime\u001B[38;5;241m.\u001B[39mnow()\u001B[38;5;241m.\u001B[39mstrftime(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mH-\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mM\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m     33\u001B[0m     filename\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{epoch:02d}\u001B[39;00m\u001B[38;5;124m-\u001B[39m\u001B[38;5;132;01m{val_loss:.2f}\u001B[39;00m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     36\u001B[0m     verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m     37\u001B[0m )\n\u001B[1;32m     39\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Trainer(\n\u001B[1;32m     40\u001B[0m     max_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m,\n\u001B[1;32m     41\u001B[0m     accelerator\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgpu\u001B[39m\u001B[38;5;124m\"\u001B[39m, \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     44\u001B[0m     callbacks\u001B[38;5;241m=\u001B[39m[checkpoint_callback],\n\u001B[1;32m     45\u001B[0m )\n\u001B[0;32m---> 47\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatamodule\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_module\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Schreibtisch/Uni/HSG/ML/EuroSatClassification/.venv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:608\u001B[0m, in \u001B[0;36mTrainer.fit\u001B[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[1;32m    606\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_unwrap_optimized(model)\n\u001B[1;32m    607\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39m_lightning_module \u001B[38;5;241m=\u001B[39m model\n\u001B[0;32m--> 608\u001B[0m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_and_handle_interrupt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    609\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_impl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatamodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\n\u001B[1;32m    610\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Schreibtisch/Uni/HSG/ML/EuroSatClassification/.venv/lib/python3.8/site-packages/pytorch_lightning/trainer/call.py:38\u001B[0m, in \u001B[0;36m_call_and_handle_interrupt\u001B[0;34m(trainer, trainer_fn, *args, **kwargs)\u001B[0m\n\u001B[1;32m     36\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher\u001B[38;5;241m.\u001B[39mlaunch(trainer_fn, \u001B[38;5;241m*\u001B[39margs, trainer\u001B[38;5;241m=\u001B[39mtrainer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     37\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 38\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtrainer_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     40\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _TunerExitException:\n\u001B[1;32m     41\u001B[0m     trainer\u001B[38;5;241m.\u001B[39m_call_teardown_hook()\n",
      "File \u001B[0;32m~/Schreibtisch/Uni/HSG/ML/EuroSatClassification/.venv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:650\u001B[0m, in \u001B[0;36mTrainer._fit_impl\u001B[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[1;32m    643\u001B[0m ckpt_path \u001B[38;5;241m=\u001B[39m ckpt_path \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresume_from_checkpoint\n\u001B[1;32m    644\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ckpt_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_checkpoint_connector\u001B[38;5;241m.\u001B[39m_set_ckpt_path(\n\u001B[1;32m    645\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn,\n\u001B[1;32m    646\u001B[0m     ckpt_path,  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[1;32m    647\u001B[0m     model_provided\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    648\u001B[0m     model_connected\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    649\u001B[0m )\n\u001B[0;32m--> 650\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mckpt_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    652\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstopped\n\u001B[1;32m    653\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/Schreibtisch/Uni/HSG/ML/EuroSatClassification/.venv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1112\u001B[0m, in \u001B[0;36mTrainer._run\u001B[0;34m(self, model, ckpt_path)\u001B[0m\n\u001B[1;32m   1108\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_checkpoint_connector\u001B[38;5;241m.\u001B[39mrestore_training_state()\n\u001B[1;32m   1110\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_checkpoint_connector\u001B[38;5;241m.\u001B[39mresume_end()\n\u001B[0;32m-> 1112\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_stage\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1114\u001B[0m log\u001B[38;5;241m.\u001B[39mdetail(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: trainer tearing down\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1115\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_teardown()\n",
      "File \u001B[0;32m~/Schreibtisch/Uni/HSG/ML/EuroSatClassification/.venv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1191\u001B[0m, in \u001B[0;36mTrainer._run_stage\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1189\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredicting:\n\u001B[1;32m   1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_predict()\n\u001B[0;32m-> 1191\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_train\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Schreibtisch/Uni/HSG/ML/EuroSatClassification/.venv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1204\u001B[0m, in \u001B[0;36mTrainer._run_train\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1201\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pre_training_routine()\n\u001B[1;32m   1203\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m isolate_rng():\n\u001B[0;32m-> 1204\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_sanity_check\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1206\u001B[0m \u001B[38;5;66;03m# enable train mode\u001B[39;00m\n\u001B[1;32m   1207\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Schreibtisch/Uni/HSG/ML/EuroSatClassification/.venv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1276\u001B[0m, in \u001B[0;36mTrainer._run_sanity_check\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1274\u001B[0m \u001B[38;5;66;03m# run eval step\u001B[39;00m\n\u001B[1;32m   1275\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m-> 1276\u001B[0m     \u001B[43mval_loop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1278\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_callback_hooks(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mon_sanity_check_end\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1280\u001B[0m \u001B[38;5;66;03m# reset logger connector\u001B[39;00m\n",
      "File \u001B[0;32m~/Schreibtisch/Uni/HSG/ML/EuroSatClassification/.venv/lib/python3.8/site-packages/pytorch_lightning/loops/loop.py:199\u001B[0m, in \u001B[0;36mLoop.run\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    197\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    198\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_advance_start(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 199\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madvance\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    200\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_advance_end()\n\u001B[1;32m    201\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_restarting \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/Schreibtisch/Uni/HSG/ML/EuroSatClassification/.venv/lib/python3.8/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py:152\u001B[0m, in \u001B[0;36mEvaluationLoop.advance\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    150\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_dataloaders \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    151\u001B[0m     kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdataloader_idx\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m dataloader_idx\n\u001B[0;32m--> 152\u001B[0m dl_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mepoch_loop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_data_fetcher\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdl_max_batches\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    154\u001B[0m \u001B[38;5;66;03m# store batch level output per dataloader\u001B[39;00m\n\u001B[1;32m    155\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_outputs\u001B[38;5;241m.\u001B[39mappend(dl_outputs)\n",
      "File \u001B[0;32m~/Schreibtisch/Uni/HSG/ML/EuroSatClassification/.venv/lib/python3.8/site-packages/pytorch_lightning/loops/loop.py:199\u001B[0m, in \u001B[0;36mLoop.run\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    197\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    198\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_advance_start(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 199\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madvance\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    200\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_advance_end()\n\u001B[1;32m    201\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_restarting \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/Schreibtisch/Uni/HSG/ML/EuroSatClassification/.venv/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py:137\u001B[0m, in \u001B[0;36mEvaluationEpochLoop.advance\u001B[0;34m(self, data_fetcher, dl_max_batches, kwargs)\u001B[0m\n\u001B[1;32m    134\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_progress\u001B[38;5;241m.\u001B[39mincrement_started()\n\u001B[1;32m    136\u001B[0m \u001B[38;5;66;03m# lightning module methods\u001B[39;00m\n\u001B[0;32m--> 137\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_evaluation_step\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    138\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_evaluation_step_end(output)\n\u001B[1;32m    140\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_progress\u001B[38;5;241m.\u001B[39mincrement_processed()\n",
      "File \u001B[0;32m~/Schreibtisch/Uni/HSG/ML/EuroSatClassification/.venv/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py:234\u001B[0m, in \u001B[0;36mEvaluationEpochLoop._evaluation_step\u001B[0;34m(self, **kwargs)\u001B[0m\n\u001B[1;32m    223\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"The evaluation step (validation_step or test_step depending on the trainer's state).\u001B[39;00m\n\u001B[1;32m    224\u001B[0m \n\u001B[1;32m    225\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    231\u001B[0m \u001B[38;5;124;03m    the outputs of the step\u001B[39;00m\n\u001B[1;32m    232\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    233\u001B[0m hook_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_step\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mtesting \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalidation_step\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m--> 234\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_strategy_hook\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhook_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalues\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    236\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output\n",
      "File \u001B[0;32m~/Schreibtisch/Uni/HSG/ML/EuroSatClassification/.venv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1494\u001B[0m, in \u001B[0;36mTrainer._call_strategy_hook\u001B[0;34m(self, hook_name, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1491\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m   1493\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mprofile(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[Strategy]\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhook_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m-> 1494\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# restore current_fx when nested context\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m pl_module\u001B[38;5;241m.\u001B[39m_current_fx_name \u001B[38;5;241m=\u001B[39m prev_fx_name\n",
      "File \u001B[0;32m~/Schreibtisch/Uni/HSG/ML/EuroSatClassification/.venv/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py:390\u001B[0m, in \u001B[0;36mStrategy.validation_step\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    388\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprecision_plugin\u001B[38;5;241m.\u001B[39mval_step_context():\n\u001B[1;32m    389\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel, ValidationStep)\n\u001B[0;32m--> 390\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalidation_step\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Schreibtisch/Uni/HSG/ML/EuroSatClassification/src/training/pretrainedModels.py:79\u001B[0m, in \u001B[0;36mEuroSatPreTrainedModel.validation_step\u001B[0;34m(self, batch, batch_idx)\u001B[0m\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mvalidation_step\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch, batch_idx):\n\u001B[1;32m     78\u001B[0m     inputs, labels \u001B[38;5;241m=\u001B[39m batch\n\u001B[0;32m---> 79\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     80\u001B[0m     _, labels \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmax(labels, \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     81\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcriterion(outputs, labels)\n",
      "File \u001B[0;32m~/Schreibtisch/Uni/HSG/ML/EuroSatClassification/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/Schreibtisch/Uni/HSG/ML/EuroSatClassification/src/training/pretrainedModels.py:67\u001B[0m, in \u001B[0;36mEuroSatPreTrainedModel.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m     66\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbackbone(x)\n\u001B[0;32m---> 67\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclassifier\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Schreibtisch/Uni/HSG/ML/EuroSatClassification/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/Schreibtisch/Uni/HSG/ML/EuroSatClassification/.venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mTypeError\u001B[0m: linear(): argument 'input' (position 1) must be Tensor, not ImageClassifierOutput"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import BackboneFinetuning, ModelCheckpoint\n",
    "from pytorch_lightning import Trainer\n",
    "from src.training.pretrainedModels import EuroSatPreTrainedModel\n",
    "from src.training.data import EuroSatDataModule\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "data_module = EuroSatDataModule(ds_train, ds_val, ds_test, BATCH_SIZE)\n",
    "print(f\"\"\"{c.OKGREEN}Initialized the data module...{c.ENDC}\"\"\")\n",
    "\n",
    "model = get_pretrained_model(m_name)\n",
    "print(model)\n",
    "\n",
    "model_train = EuroSatPreTrainedModel(\n",
    "    backbone=model,\n",
    "    learning_rate=0.1,\n",
    "    layers=[],\n",
    "    gamma=0.7,\n",
    "    momentum=0.9,\n",
    "    dropout=0.3,\n",
    "    weight_decay=1e-3\n",
    ")\n",
    "\n",
    "logger = WandbLogger(\n",
    "    project=\"eurosat_resnet\",\n",
    "    name=m_name,\n",
    "    log_model=False,\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=CKPT_PATH + datetime.now().strftime(\"%H-%M\"),\n",
    "    filename='{epoch:02d}-{val_loss:.2f}',\n",
    "    save_top_k=2, \n",
    "    monitor=\"val_loss\",\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=5,\n",
    "    accelerator=\"gpu\", \n",
    "    devices=1,\n",
    "    logger=logger,\n",
    "    callbacks=[checkpoint_callback],\n",
    ")\n",
    "\n",
    "trainer.fit(model_train, datamodule=data_module)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:46:35.587080Z",
     "start_time": "2024-03-21T16:46:24.920028Z"
    }
   },
   "id": "efb3d4dce1d9c8f8",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from torchsummary import summary\n",
    "\n",
    "# summary(model_train.classifier.cuda(), (1000, ))\n",
    "\n",
    "trainer.test(model_train, datamodule=data_module, ckpt_path=checkpoint_callback.best_model_path)\n",
    "\n",
    "all_preds = np.concatenate(model_train.ep_out)\n",
    "all_true = np.concatenate(model_train.ep_true)\n",
    "true_ep = torch.tensor(all_true)\n",
    "pred_ep = torch.tensor(all_preds)\n",
    "\n",
    "metric = torchmetrics.ConfusionMatrix(task=\"multiclass\", num_classes=NUM_CLASSES)\n",
    "metric.update(pred_ep, true_ep)\n",
    "confmat = metric.compute()\n",
    "confmat_np = confmat.numpy()\n",
    "tick_labels = [encoder.categories_[0][i] for i in range(NUM_CLASSES)]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(confmat_np, annot=True, fmt='g', cmap='Blues', \n",
    "            xticklabels=tick_labels, yticklabels=tick_labels)\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a744160ec48183d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "from src.training.pretrainedModels import EuroSatPreTrainedModel\n",
    "from datetime import datetime\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import BackboneFinetuning, ModelCheckpoint\n",
    "from pytorch_lightning import Trainer\n",
    "from src.training.data import EuroSatDataModule\n",
    "import random\n",
    "import numpy as np\n",
    "import wandb\n",
    "\n",
    "n_rounds = 20\n",
    "gamma = 0.95\n",
    "momentum = 0.9\n",
    "dropout = 0.5\n",
    "weight_decay = 5e-3\n",
    "\n",
    "layers_samples = [[], [256]]\n",
    "\n",
    "lr_samples = [0.3, 0.1, 0.05, 0.01]\n",
    "\n",
    "bs_samples = [32, 64, 128]\n",
    "\n",
    "param_space = [[l, b, la] for l in lr_samples for b in bs_samples for la in layers_samples]\n",
    "random.shuffle(param_space)\n",
    "\n",
    "out_table = []\n",
    "\n",
    "for i in range(n_rounds):\n",
    "    lr_hp, bs_hp, layers_hp = param_space[i]\n",
    "    \n",
    "    print(f\"{c.OKBLUE}Round {i+1}/{n_rounds}{c.ENDC}\")\n",
    "    print(f\"{c.OKBLUE}Learning Rate: {lr_hp:.4f}, Batch Size: {bs_hp}, Layers: {layers_hp}{c.ENDC}\")\n",
    "    \n",
    "    data_module = EuroSatDataModule(ds_train, ds_val, ds_test, bs_hp)\n",
    "    \n",
    "    model = get_pretrained_model(m_name)\n",
    "    model_train = EuroSatPreTrainedModel(\n",
    "        backbone=model,\n",
    "        layers=layers_hp,\n",
    "        learning_rate=lr_hp,\n",
    "        gamma=gamma,\n",
    "        momentum=momentum,\n",
    "        dropout=dropout,\n",
    "        weight_decay=weight_decay\n",
    "    )\n",
    "    \n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=CKPT_PATH + \"hp_tuning\" + f\"/round_{i}\",\n",
    "        filename=f\"bs_{bs_hp}_lr_{lr_hp}_ly_{layers_hp}_loss_\" + '{val_loss:.2f}',\n",
    "        save_top_k=1, \n",
    "        monitor=\"val_loss\",\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    wandb_logger = WandbLogger(\n",
    "        project=\"eurosat_resnet\",\n",
    "        name=f\"bs_{bs_hp}_lr_{round(lr_hp, 4)}_ly_{len(layers_hp)}\",\n",
    "        log_model=False,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        max_epochs=2,\n",
    "        accelerator=\"gpu\", \n",
    "        devices=1,\n",
    "        logger=wandb_logger,\n",
    "        callbacks=[checkpoint_callback],\n",
    "    )\n",
    "\n",
    "    trainer.fit(model_train, datamodule=data_module)\n",
    "    trainer.test(model_train, datamodule=data_module, ckpt_path=checkpoint_callback.best_model_path, verbose=False)\n",
    "    score = model_train.accuracy\n",
    "    out_table.append([lr_hp, bs_hp, layers_hp, score])\n",
    "    print(tabulate(out_table, headers=[\"Learning Rate\", \"Batch Size\", \"Layers\", \"Accuracy\"]))\n",
    "    wandb.finish()\n",
    "    \n",
    "print(tabulate(out_table, headers=[\"Learning Rate\", \"Batch Size\", \"Layers\", \"Accuracy\"]))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28a7c062d1e82c9e",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Predict on the test set"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d14c14d786b83fa8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from src.datasets.EuroSatTest import EuroSatTestSet\n",
    "from torch.utils.data import DataLoader\n",
    "from config import Config\n",
    "\n",
    "config = Config()\n",
    "\n",
    "# CHANNELS = [11, 10, 8, 7, 6, 5, 4, 3, 2, 1, 0]\n",
    "CHANNELS = [3, 2, 1]\n",
    "\n",
    "dataset = EuroSatTestSet(config.TEST_MS_DIR, select_chan=CHANNELS, add_b10=False) #, augment=aug)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=False)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fbe578b12c3ba259",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from src.training.pretrainedModels import EuroSatPreTrainedModel\n",
    "from src.training.cnn import LitEuroSatCnn\n",
    "from config import Config\n",
    "\n",
    "config = Config()\n",
    "\n",
    "# model_eval = LitEuroSatCnn.load_from_checkpoint(\n",
    "#     \"checkpoints/cnn/14-18/cnn_c87654_k53_lr0.03_m0.9_g0.8epoch=09-val_loss=0.68.ckpt\", #checkpoint_callback.best_model_path,\n",
    "#     num_classes=NUM_CLASSES,\n",
    "#     learning_rate=0.025, \n",
    "#     num_channels=len(CHANNELS), \n",
    "#     kernel_size=[5, 3],\n",
    "#     momentum=0.9,\n",
    "#     gamma=0.9,\n",
    "#     weights=torch.tensor(w, dtype=torch.float32)\n",
    "# )\n",
    "\n",
    "\n",
    "model = get_pretrained_model(m_name)\n",
    "model_eval = EuroSatPreTrainedModel.load_from_checkpoint(\n",
    "    checkpoint_callback.best_model_path,\n",
    "    backbone=model,\n",
    "    learning_rate=1e-4,\n",
    "    layers=[],\n",
    "    momentum=0.9,\n",
    "    dropout=0,\n",
    "    weight_decay=0.0001\n",
    ")\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model_eval.eval()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b042a06f7a52870c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_eval = model_eval.to(device)\n",
    "model_eval.eval()\n",
    "\n",
    "N_CLASSES = 10\n",
    "categorys = dataset.enc.categories_[0]\n",
    "print(categorys)\n",
    "\n",
    "predictions = []\n",
    "probabilities = []\n",
    "ohe = []\n",
    "images = []\n",
    "sample_ids = []\n",
    "\n",
    "rounds = 3\n",
    "\n",
    "    \n",
    "with torch.no_grad():\n",
    "    for batch in dataloader:\n",
    "        inputs, samp_id = batch\n",
    "        inputs = inputs.to(device)\n",
    "            \n",
    "        outputs = model_eval(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        preds = np.array(preds.cpu().numpy())\n",
    "        \n",
    "        pred_labels = np.array([categorys[p] for p in preds])\n",
    "        \n",
    "        predictions.extend(pred_labels)\n",
    "        images.extend(inputs.cpu())\n",
    "        sample_ids.extend(samp_id.cpu())\n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "194979db7753d23d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "sub_df = pd.DataFrame({'test_id': np.array(sample_ids), 'label': np.array(predictions)})\n",
    "sub_df = sub_df.sort_values(by='test_id')\n",
    "print(sub_df.head())\n",
    "print(np.array(sample_ids))\n",
    "\n",
    "sub_df.to_csv('submission.csv', index=False)\n",
    "print(np.unique(predictions, return_counts=True))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "58b692ad612e50fa",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.nn.functional import interpolate\n",
    "\n",
    "\n",
    "def overlay_cam_on_image(im, cam_mask):\n",
    "    cam_mask = (cam_mask - cam_mask.min()) / (cam_mask.max() - cam_mask.min())\n",
    "    print(cam_mask.shape)\n",
    "    print(im.shape)\n",
    "    # Resize the CAM mask to match the image size\n",
    "    cam_mask = interpolate(cam_mask, size=im.shape, mode='nearest').squeeze(0)\n",
    "    print(im.shape)\n",
    "    print(cam_mask.shape)\n",
    "    # Convert CAM mask to heatmap\n",
    "    heatmap = plt.get_cmap('jet')(cam_mask.cpu().detach().numpy())[:, :, :3]  # Get the RGB part, discard alpha\n",
    "    heatmap = torch.from_numpy(heatmap).permute(2, 0, 1).float()\n",
    "\n",
    "    # Overlay the heatmap on the image\n",
    "    combined_img = heatmap * 0.3 + im.cpu() * 0.5  # Adjust opacity as needed\n",
    "\n",
    "    return combined_img"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af1903acbac15b5a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from pytorch_grad_cam import GradCAM\n",
    "\n",
    "import torch\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "grad_cam_c = False\n",
    "samp_batch_idx = [i for i in range(0, len(sample_ids))]\n",
    "random.shuffle(samp_batch_idx)\n",
    "samp_batch_idx = np.array(samp_batch_idx)\n",
    "n = 3\n",
    "\n",
    "for param in model_eval.backbone.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "\n",
    "target_layer = [model_eval.backbone.layer4[-1].conv1]\n",
    "\n",
    "\n",
    "for batch_start in range(0, n*8, 8):  # Iterate in steps of 8\n",
    "    fig, axs = plt.subplots(2, 4, figsize=(20, 10))  # Create a new figure for each batch\n",
    "    axs = axs.flatten()  # Flatten the grid for easy iteration\n",
    "\n",
    "    for idx, ax in zip(samp_batch_idx[batch_start:batch_start+8], axs):\n",
    "        pred = predictions[idx]\n",
    "        samp_id = sample_ids[idx]\n",
    "        \n",
    "        im_path = f\"data/test/NoLabel/test_{samp_id}.npy\"\n",
    "        img = images[idx].unsqueeze(0).requires_grad_(True).to(device)\n",
    "        \n",
    "        \n",
    "        \n",
    "        ax.imshow(images[idx].cpu().numpy().transpose(1, 2, 0))\n",
    "        if grad_cam_c:\n",
    "            img = images[idx].unsqueeze(0).requires_grad_(True).to(device)\n",
    "            cam = GradCAM(model=model_eval, target_layers=target_layer)\n",
    "            grayscale_cam = cam(input_tensor=img, targets=None)\n",
    "            cam_mask_tensor = torch.tensor(grayscale_cam).unsqueeze(0)\n",
    "            ax.imshow(cam_mask_tensor.squeeze(0).squeeze(0).cpu().numpy(), cmap='jet', alpha=0.1)\n",
    "        else:\n",
    "            ax.imshow(images[idx].cpu().numpy().transpose(1, 2, 0))\n",
    "        ax.set_title(pred, fontsize=20)\n",
    "        ax.axis('off')\n",
    "        \n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(wspace=0.2, hspace=0.2)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e11bec6bf308538",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3e98d855fa7c2c67"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
