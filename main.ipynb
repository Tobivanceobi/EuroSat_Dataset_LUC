{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Load the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c96e1dbdb152f98"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-22T15:13:30.243291Z",
     "start_time": "2024-03-22T15:13:30.239527Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.colors import bcolors\n",
    "from config import Config\n",
    "\n",
    "c = bcolors()\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import kornia.augmentation as K\n",
    "import torch\n",
    "from src.pickle_loader import load_object, save_object\n",
    "\n",
    "stats = load_object(\"../data/eurosat_ms_mean_std\")\n",
    "mean = stats['mean']\n",
    "std = stats['std']\n",
    "chan_idx = stats['idx']\n",
    "\n",
    "# CHANNELS = [12, 11, 8, 7]\n",
    "CHANNELS = [3, 2, 1]\n",
    "NUM_CLASSES = 10\n",
    "NUM_AUG = 1\n",
    "\n",
    "df = pd.read_csv(config.TRAIN_FILE)\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "encoder = encoder.fit(df[['label']].values.reshape(-1, 1))\n",
    "save_object(encoder, \"../data/on_hot_encoder\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T15:13:34.271115Z",
     "start_time": "2024-03-22T15:13:32.905235Z"
    }
   },
   "id": "ea2db869e77d2168",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AnnualCrop' 'Forest' 'HerbaceousVegetation' 'Highway' 'Industrial'\n",
      " 'Pasture' 'PermanentCrop' 'Residential' 'River' 'SeaLake']\n",
      "\n",
      "\u001B[92mPreloading images...\u001B[0m\n",
      "\n",
      "\u001B[96mImages:         21600\u001B[0m\n",
      "\u001B[96mAugmentations:  21600\u001B[0m\n",
      "\u001B[96mJobs:           -4 \u001B[0m\n",
      "\n",
      "\u001B[94mTime taken:      0 min 17.378334760665894 sec \u001B[0m\n",
      "\n",
      "\u001B[92mPreloading images...\u001B[0m\n",
      "\n",
      "\u001B[96mImages:         3780\u001B[0m\n",
      "\u001B[96mAugmentations:  3780\u001B[0m\n",
      "\u001B[96mJobs:           -4 \u001B[0m\n",
      "\n",
      "\u001B[94mTime taken:      0 min 2.21551251411438 sec \u001B[0m\n",
      "\n",
      "\u001B[92mPreloading images...\u001B[0m\n",
      "\n",
      "\u001B[96mImages:         1620\u001B[0m\n",
      "\u001B[96mAugmentations:  1620\u001B[0m\n",
      "\u001B[96mJobs:           -4 \u001B[0m\n",
      "\n",
      "\u001B[94mTime taken:      0 min 1.9306273460388184 sec \u001B[0m\n",
      "\n",
      "\u001B[92mTrain dataset:   21600 samples\u001B[0m\n",
      "\u001B[92mValidation dataset: 3780 samples\u001B[0m\n",
      "\u001B[92mTest dataset:       1620 samples\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from src.datasets.EuroSatMS import EuroSatMS\n",
    "\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['label'])\n",
    "print(df['label'].unique())\n",
    "test_df, val_df = train_test_split(val_df, test_size=0.7)\n",
    "\n",
    "ds_train = EuroSatMS(\n",
    "    train_df, \n",
    "    config.TRAIN_MS_DIR,\n",
    "    encoder=encoder,\n",
    "    num_aug=NUM_AUG, \n",
    "    select_chan=CHANNELS\n",
    ")\n",
    "\n",
    "ds_val = EuroSatMS(\n",
    "    val_df, \n",
    "    config.TRAIN_MS_DIR,\n",
    "    encoder=encoder,\n",
    "    num_aug=NUM_AUG, \n",
    "    select_chan=CHANNELS\n",
    ")\n",
    "\n",
    "ds_test = EuroSatMS(\n",
    "    test_df, \n",
    "    config.TRAIN_MS_DIR,\n",
    "    encoder=encoder,\n",
    "    num_aug=NUM_AUG, \n",
    "    select_chan=CHANNELS\n",
    ")\n",
    "\n",
    "print(f\"\"\"\\n{c.OKGREEN}Train dataset:   {len(ds_train)} samples{c.ENDC}\"\"\")\n",
    "print(f\"\"\"{c.OKGREEN}Validation dataset: {len(ds_val)} samples{c.ENDC}\"\"\")\n",
    "print(f\"\"\"{c.OKGREEN}Test dataset:       {len(ds_test)} samples{c.ENDC}\"\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T15:13:58.114004Z",
     "start_time": "2024-03-22T15:13:35.340334Z"
    }
   },
   "id": "89850dd26de91e3a",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "transform_mean_std = transforms.Compose([\n",
    "    K.Normalize(mean=mean[CHANNELS], std=std[CHANNELS])\n",
    "])\n",
    "\n",
    "p1 = 0.5\n",
    "p2 = 0.6\n",
    "p3 = 0.6\n",
    "augmentation = nn.Sequential(\n",
    "    K.RandomHorizontalFlip(p=p3),\n",
    "    K.RandomVerticalFlip(p=p3),\n",
    "    K.RandomAffine(degrees=45, translate=None, scale=None, shear=None, resample=\"nearest\", padding_mode=2, p=p2),\n",
    "    K.RandomShear(shear=0.3, resample=\"nearest\", padding_mode=2, p=p2),\n",
    "    K.RandomContrast(contrast=(0.8, 1.2), p=p1),\n",
    "    K.RandomBrightness((0.7, 1.3), p=p2),\n",
    "    # K.RandomPlasmaContrast(roughness=(0.1, 0.4), p=p1),\n",
    "    # K.RandomSolarize(thresholds=0.1, p=p1),\n",
    "    K.RandomSaturation((0.9, 1.1), p=p1),\n",
    "    # K.RandomBoxBlur(kernel_size=(3, 3), p=p1),\n",
    "    #K.RandomEqualize(p=p1),\n",
    "    K.CenterCrop(size=(64, 64))\n",
    ")\n",
    "\n",
    "ds_train.augment = augmentation\n",
    "ds_val.augment = None\n",
    "ds_test.augment = None\n",
    "\n",
    "ds_train.transform = None\n",
    "ds_val.transform = None\n",
    "ds_test.transform = None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T15:14:02.184495Z",
     "start_time": "2024-03-22T15:14:02.168048Z"
    }
   },
   "id": "a5e5a55b27ee41b1",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CNN Model Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "693660b793045e2a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from src.training.data import EuroSatDataModule\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "data_module = EuroSatDataModule(ds_train, ds_val, ds_test, BATCH_SIZE)\n",
    "print(f\"\"\"{c.OKGREEN}Initialized the data module...{c.ENDC}\"\"\")\n",
    "\n",
    "KERNEL_SIZE = [5, 3]\n",
    "LEARNING_RATE = 0.03\n",
    "MOMENTUM = 0.9\n",
    "GAMMA = 0.9\n",
    "DROPOUT = 0.3\n",
    "EPOCHS = 15\n",
    "CKPT_PATH = 'checkpoints/cnn/'\n",
    "CLASS_WEIGHTS = {'AnnualCrop': 9,\n",
    "                 'Forest': 9,\n",
    "                 'HerbaceousVegetation': 8, \n",
    "                 'Highway': 9, \n",
    "                 'Industrial': 9,\n",
    "                 'Pasture': 9, \n",
    "                 'PermanentCrop': 9, \n",
    "                 'Residential': 9, \n",
    "                 'River': 9, \n",
    "                 'SeaLake': 9}\n",
    "\n",
    "w = np.array(list(CLASS_WEIGHTS.values()))\n",
    "w_min, w_max = w.min(), w.max()\n",
    "w = (w - w_min) / (w_max - w_min)\n",
    "\n",
    "fname = \"cnn_c\"\n",
    "for c in CHANNELS:\n",
    "    fname += str(c)\n",
    "fname += \"_k\"\n",
    "for k in KERNEL_SIZE:\n",
    "    fname += str(k)\n",
    "fname += \"_lr\" + str(LEARNING_RATE)\n",
    "fname += \"_m\" + str(MOMENTUM)\n",
    "fname += \"_g\" + str(GAMMA)\n",
    "fname += \"_d\" + str(DROPOUT)\n",
    "\n",
    "print(\"Model name: \", fname)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ccb6a56d1d57dfe3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import BackboneFinetuning, ModelCheckpoint\n",
    "from src.training.cnn import LitEuroSatCnn\n",
    "from datetime import datetime\n",
    "\n",
    "lightning_model = LitEuroSatCnn(\n",
    "    num_classes=NUM_CLASSES,\n",
    "    learning_rate=LEARNING_RATE, \n",
    "    num_channels=len(CHANNELS), \n",
    "    kernel_size=KERNEL_SIZE,\n",
    "    momentum=MOMENTUM,\n",
    "    gamma=GAMMA,\n",
    "    weights=torch.tensor(w, dtype=torch.float32),\n",
    "    dropout=DROPOUT\n",
    ")\n",
    "\n",
    "logger = WandbLogger(\n",
    "    project=\"eurosat_cnn\",\n",
    "    name=\"cnn_v1\",\n",
    "    log_model=False,\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=CKPT_PATH + datetime.now().strftime(\"%H-%M\"),\n",
    "    filename=fname + '_{epoch:02d}-{val_loss:.2f}',\n",
    "    save_top_k=2, \n",
    "    monitor=\"val_loss\",\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=EPOCHS,\n",
    "    accelerator=\"gpu\", \n",
    "    devices=1,\n",
    "    logger=logger,\n",
    "    callbacks=[checkpoint_callback],\n",
    ")\n",
    "\n",
    "trainer.fit(lightning_model, datamodule=data_module)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa70fc0415fe6817",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "trainer.test(lightning_model, datamodule=data_module, ckpt_path=checkpoint_callback.best_model_path)\n",
    "metric = torchmetrics.ConfusionMatrix(task=\"multiclass\", num_classes=NUM_CLASSES)\n",
    "all_preds = np.concatenate(lightning_model.ep_out)\n",
    "all_true = np.concatenate(lightning_model.ep_true)\n",
    "true_ep = torch.tensor(all_true)\n",
    "pred_ep = torch.tensor(all_preds)\n",
    "metric.update(pred_ep, true_ep)\n",
    "fig, ax = metric.plot()\n",
    "plt.show()\n",
    "print(encoder.categories_[0])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2bb7804baa9a7fa0",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2e31138fe1fbd612"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pretrained Model Training\n",
    "### Training Phase 1\n",
    "##### Pretrained ResNet50, ResNet18, AlexNet Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7460c6672b1ff7c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torchvision.transforms import InterpolationMode\n",
    "from torchvision.models import ViT_H_14_Weights, ViT_B_16_Weights, ViT_B_32_Weights, ViT_L_16_Weights, ViT_L_32_Weights\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torchgeo.models as models\n",
    "from torchgeo.models import ResNet18_Weights, ResNet50_Weights\n",
    "\n",
    "\n",
    "def get_pretrained_model(model_name):\n",
    "    if model_name == \"B13_rn50_moco_0099\":\n",
    "        m = models.resnet50(weights=None)\n",
    "        m.fc = nn.Linear(2048,19)\n",
    "        m.conv1 = nn.Conv2d(\n",
    "            13, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
    "        )\n",
    "        ckp = torch.load(\"B13_rn50_moco_0099.pth\", map_location=\"cpu\")\n",
    "        sd = ckp['state_dict']\n",
    "        \n",
    "        for key in list(sd.keys()):\n",
    "            if key.startswith('module.encoder_q') and not key.startswith('module.encoder_q.fc'):\n",
    "                sd[key[len(\"module.encoder_q.\"):]] = sd[key]\n",
    "            del sd[key]\n",
    "        \n",
    "        msg = m.load_state_dict(sd, strict=False)\n",
    "        assert set(msg.missing_keys) == {\"fc.weight\", \"fc.bias\"}\n",
    "        \n",
    "        return m, None\n",
    "    elif \"resnet18_RGB_MOCO\" in model_name:\n",
    "        return models.resnet18(weights=ResNet18_Weights.SENTINEL2_RGB_MOCO), None\n",
    "    elif \"resnet50_RGB_MOCO\" in model_name:\n",
    "        return models.resnet50(weights=ResNet50_Weights.SENTINEL2_RGB_MOCO), None\n",
    "    elif \"resnet50_MS_SECO\" in model_name:\n",
    "        return models.resnet50(weights=ResNet50_Weights.SENTINEL2_RGB_SECO), None\n",
    "    elif \"vit_h_14\" in model_name:\n",
    "        tf = transforms.Compose([\n",
    "            transforms.Resize(518, interpolation=InterpolationMode.BICUBIC),\n",
    "            transforms.CenterCrop(518),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        return torchvision.models.vit_h_14(weights=ViT_H_14_Weights.IMAGENET1K_SWAG_E2E_V1), tf\n",
    "    elif \"vit_b_16\" in model_name:\n",
    "        tf = transforms.Compose([\n",
    "            transforms.Resize(256, interpolation=InterpolationMode.BILINEAR),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        return torchvision.models.vit_b_16(weights=ViT_B_16_Weights.IMAGENET1K_V1), tf\n",
    "    elif \"vit_b_32\" in model_name:\n",
    "        tf = transforms.Compose([\n",
    "            transforms.Resize(256, interpolation=InterpolationMode.BILINEAR),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        return torchvision.models.vit_b_32(weights=ViT_B_32_Weights.IMAGENET1K_V1), tf\n",
    "    elif \"vit_l_16\" in model_name:\n",
    "        tf = transforms.Compose([\n",
    "            transforms.Resize(242, interpolation=InterpolationMode.BILINEAR),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        return torchvision.models.vit_l_16(weights=ViT_L_16_Weights.IMAGENET1K_V1), tf\n",
    "    elif \"vit_l_32\" in model_name:\n",
    "        tf = transforms.Compose([\n",
    "            transforms.Resize(256, interpolation=InterpolationMode.BILINEAR),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        return torchvision.models.vit_l_32(weights=ViT_L_32_Weights.IMAGENET1K_V1), tf\n",
    "\n",
    "m_name = \"vit_l_32\"\n",
    "CKPT_PATH = f'checkpoints/{m_name}/'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T15:14:26.771104Z",
     "start_time": "2024-03-22T15:14:24.298601Z"
    }
   },
   "id": "a7506054d07ddabd",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92mPreparing the backbone and setting transforms...\u001B[0m\n",
      "\u001B[92mInitialized the data module...\u001B[0m\n",
      "VisionTransformer(\n",
      "  (conv_proj): Conv2d(3, 1024, kernel_size=(32, 32), stride=(32, 32))\n",
      "  (encoder): Encoder(\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "    (layers): Sequential(\n",
      "      (encoder_layer_0): EncoderBlock(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_1): EncoderBlock(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_2): EncoderBlock(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_3): EncoderBlock(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_4): EncoderBlock(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_5): EncoderBlock(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_6): EncoderBlock(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_7): EncoderBlock(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_8): EncoderBlock(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_9): EncoderBlock(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_10): EncoderBlock(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_11): EncoderBlock(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_12): EncoderBlock(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_13): EncoderBlock(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_14): EncoderBlock(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_15): EncoderBlock(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_16): EncoderBlock(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_17): EncoderBlock(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_18): EncoderBlock(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_19): EncoderBlock(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_20): EncoderBlock(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_21): EncoderBlock(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_22): EncoderBlock(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_23): EncoderBlock(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (heads): Sequential(\n",
      "    (head): Linear(in_features=1024, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "from src.training.data import EuroSatDataModule\n",
    "from src.training.pretrainedModels import EuroSatPreTrainedModel\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "print(f\"\"\"{c.OKGREEN}Preparing the backbone and setting transforms...{c.ENDC}\"\"\")\n",
    "model, transform = get_pretrained_model(m_name)\n",
    "\n",
    "ds_train.transform = transform\n",
    "ds_val.transform = transform\n",
    "ds_test.transform = transform\n",
    "\n",
    "data_module = EuroSatDataModule(ds_train, ds_val, ds_test, BATCH_SIZE)\n",
    "print(f\"\"\"{c.OKGREEN}Initialized the data module...{c.ENDC}\"\"\")\n",
    "print(model)\n",
    "model_train = EuroSatPreTrainedModel(\n",
    "    backbone=model,\n",
    "    learning_rate=0.01,\n",
    "    layers=[],\n",
    "    gamma=0.9,\n",
    "    momentum=0.9,\n",
    "    dropout=0.3,\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "# summary(model_train.classifier.cuda(), (1000, ))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T15:17:59.367228Z",
     "start_time": "2024-03-22T15:17:54.985415Z"
    }
   },
   "id": "42a5f7c4ad819ffe",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type              | Params\n",
      "-------------------------------------------------\n",
      "0 | backbone   | VisionTransformer | 305 M \n",
      "1 | classifier | Linear            | 10.2 K\n",
      "2 | criterion  | CrossEntropyLoss  | 0     \n",
      "-------------------------------------------------\n",
      "10.2 K    Trainable params\n",
      "305 M     Non-trainable params\n",
      "305 M     Total params\n",
      "1,222.083 Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b423ede9a4114e019451dc061f6375be"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f51cec4a9066484ba60c30ecbe819916"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tobias/Desktop/Uni/SS24/ML/EuroSat_Dataset_LUC/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "# logger = WandbLogger(\n",
    "#     project=\"eurosat_vit\",\n",
    "#     name=m_name,\n",
    "#     log_model=False,\n",
    "# )\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=CKPT_PATH + datetime.now().strftime(\"%H-%M\"),\n",
    "    filename='{epoch:02d}-{val_loss:.2f}',\n",
    "    save_top_k=2, \n",
    "    monitor=\"val_loss\",\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=3,\n",
    "    accelerator=\"gpu\", \n",
    "    devices=1,\n",
    "    # logger=logger,\n",
    "    callbacks=[checkpoint_callback],\n",
    ")\n",
    "\n",
    "trainer.fit(model_train, datamodule=data_module)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T15:18:24.201112Z",
     "start_time": "2024-03-22T15:18:01.889152Z"
    }
   },
   "id": "efb3d4dce1d9c8f8",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "trainer.test(model_train, datamodule=data_module, ckpt_path=checkpoint_callback.best_model_path)\n",
    "\n",
    "all_preds = np.concatenate(model_train.ep_out)\n",
    "all_true = np.concatenate(model_train.ep_true)\n",
    "true_ep = torch.tensor(all_true)\n",
    "pred_ep = torch.tensor(all_preds)\n",
    "\n",
    "metric = torchmetrics.ConfusionMatrix(task=\"multiclass\", num_classes=NUM_CLASSES)\n",
    "metric.update(pred_ep, true_ep)\n",
    "confmat = metric.compute()\n",
    "confmat_np = confmat.numpy()\n",
    "tick_labels = [encoder.categories_[0][i] for i in range(NUM_CLASSES)]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(confmat_np, annot=True, fmt='g', cmap='Blues', \n",
    "            xticklabels=tick_labels, yticklabels=tick_labels)\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a744160ec48183d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "from src.training.pretrainedModels import EuroSatPreTrainedModel\n",
    "from datetime import datetime\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import BackboneFinetuning, ModelCheckpoint\n",
    "from pytorch_lightning import Trainer\n",
    "from src.training.data import EuroSatDataModule\n",
    "import random\n",
    "import numpy as np\n",
    "import wandb\n",
    "\n",
    "n_rounds = 20\n",
    "gamma = 0.95\n",
    "momentum = 0.9\n",
    "dropout = 0.5\n",
    "weight_decay = 5e-3\n",
    "\n",
    "layers_samples = [[], [256]]\n",
    "\n",
    "lr_samples = [0.3, 0.1, 0.05, 0.01]\n",
    "\n",
    "bs_samples = [32, 64, 128]\n",
    "\n",
    "param_space = [[l, b, la] for l in lr_samples for b in bs_samples for la in layers_samples]\n",
    "random.shuffle(param_space)\n",
    "\n",
    "out_table = []\n",
    "\n",
    "for i in range(n_rounds):\n",
    "    lr_hp, bs_hp, layers_hp = param_space[i]\n",
    "    \n",
    "    print(f\"{c.OKBLUE}Round {i+1}/{n_rounds}{c.ENDC}\")\n",
    "    print(f\"{c.OKBLUE}Learning Rate: {lr_hp:.4f}, Batch Size: {bs_hp}, Layers: {layers_hp}{c.ENDC}\")\n",
    "    \n",
    "    data_module = EuroSatDataModule(ds_train, ds_val, ds_test, bs_hp)\n",
    "    \n",
    "    model = get_pretrained_model(m_name)\n",
    "    model_train = EuroSatPreTrainedModel(\n",
    "        backbone=model,\n",
    "        layers=layers_hp,\n",
    "        learning_rate=lr_hp,\n",
    "        gamma=gamma,\n",
    "        momentum=momentum,\n",
    "        dropout=dropout,\n",
    "        weight_decay=weight_decay\n",
    "    )\n",
    "    \n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=CKPT_PATH + \"hp_tuning\" + f\"/round_{i}\",\n",
    "        filename=f\"bs_{bs_hp}_lr_{lr_hp}_ly_{layers_hp}_loss_\" + '{val_loss:.2f}',\n",
    "        save_top_k=1, \n",
    "        monitor=\"val_loss\",\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    wandb_logger = WandbLogger(\n",
    "        project=\"eurosat_resnet\",\n",
    "        name=f\"bs_{bs_hp}_lr_{round(lr_hp, 4)}_ly_{len(layers_hp)}\",\n",
    "        log_model=False,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        max_epochs=2,\n",
    "        accelerator=\"gpu\", \n",
    "        devices=1,\n",
    "        logger=wandb_logger,\n",
    "        callbacks=[checkpoint_callback],\n",
    "    )\n",
    "\n",
    "    trainer.fit(model_train, datamodule=data_module)\n",
    "    trainer.test(model_train, datamodule=data_module, ckpt_path=checkpoint_callback.best_model_path, verbose=False)\n",
    "    score = model_train.accuracy\n",
    "    out_table.append([lr_hp, bs_hp, layers_hp, score])\n",
    "    print(tabulate(out_table, headers=[\"Learning Rate\", \"Batch Size\", \"Layers\", \"Accuracy\"]))\n",
    "    wandb.finish()\n",
    "    \n",
    "print(tabulate(out_table, headers=[\"Learning Rate\", \"Batch Size\", \"Layers\", \"Accuracy\"]))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28a7c062d1e82c9e",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Predict on the test set"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d14c14d786b83fa8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from src.datasets.EuroSatTest import EuroSatTestSet\n",
    "from torch.utils.data import DataLoader\n",
    "from config import Config\n",
    "\n",
    "config = Config()\n",
    "\n",
    "# CHANNELS = [11, 10, 8, 7, 6, 5, 4, 3, 2, 1, 0]\n",
    "CHANNELS = [3, 2, 1]\n",
    "\n",
    "dataset = EuroSatTestSet(config.TEST_MS_DIR, select_chan=CHANNELS, add_b10=False) #, augment=aug)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=False)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fbe578b12c3ba259",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from src.training.pretrainedModels import EuroSatPreTrainedModel\n",
    "from src.training.cnn import LitEuroSatCnn\n",
    "from config import Config\n",
    "\n",
    "config = Config()\n",
    "\n",
    "# model_eval = LitEuroSatCnn.load_from_checkpoint(\n",
    "#     \"checkpoints/cnn/14-18/cnn_c87654_k53_lr0.03_m0.9_g0.8epoch=09-val_loss=0.68.ckpt\", #checkpoint_callback.best_model_path,\n",
    "#     num_classes=NUM_CLASSES,\n",
    "#     learning_rate=0.025, \n",
    "#     num_channels=len(CHANNELS), \n",
    "#     kernel_size=[5, 3],\n",
    "#     momentum=0.9,\n",
    "#     gamma=0.9,\n",
    "#     weights=torch.tensor(w, dtype=torch.float32)\n",
    "# )\n",
    "\n",
    "\n",
    "model, transform = get_pretrained_model(m_name)\n",
    "model_eval = EuroSatPreTrainedModel.load_from_checkpoint(\n",
    "    \"checkpoints/vit_b_16/14-56/epoch=03-val_loss=0.53.ckpt\", #checkpoint_callback.best_model_path,\n",
    "    backbone=model,\n",
    "    learning_rate=1e-4,\n",
    "    layers=[],\n",
    "    momentum=0.9,\n",
    "    dropout=0,\n",
    "    weight_decay=0.0001\n",
    ")\n",
    "\n",
    "dataset.transform = transform\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model_eval.eval()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b042a06f7a52870c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_eval = model_eval.to(device)\n",
    "model_eval.eval()\n",
    "\n",
    "N_CLASSES = 10\n",
    "categorys = dataset.enc.categories_[0]\n",
    "print(categorys)\n",
    "\n",
    "predictions = []\n",
    "probabilities = []\n",
    "ohe = []\n",
    "images = []\n",
    "sample_ids = []\n",
    "\n",
    "rounds = 3\n",
    "\n",
    "    \n",
    "with torch.no_grad():\n",
    "    for batch in dataloader:\n",
    "        inputs, samp_id = batch\n",
    "        inputs = inputs.to(device)\n",
    "            \n",
    "        outputs = model_eval(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        preds = np.array(preds.cpu().numpy())\n",
    "        \n",
    "        pred_labels = np.array([categorys[p] for p in preds])\n",
    "        \n",
    "        predictions.extend(pred_labels)\n",
    "        images.extend(inputs.cpu())\n",
    "        sample_ids.extend(samp_id.cpu())\n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "194979db7753d23d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "sub_df = pd.DataFrame({'test_id': np.array(sample_ids), 'label': np.array(predictions)})\n",
    "sub_df = sub_df.sort_values(by='test_id')\n",
    "print(sub_df.head())\n",
    "print(np.array(sample_ids))\n",
    "\n",
    "sub_df.to_csv('submission.csv', index=False)\n",
    "print(np.unique(predictions, return_counts=True))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "58b692ad612e50fa",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.nn.functional import interpolate\n",
    "\n",
    "\n",
    "def overlay_cam_on_image(im, cam_mask):\n",
    "    cam_mask = (cam_mask - cam_mask.min()) / (cam_mask.max() - cam_mask.min())\n",
    "    print(cam_mask.shape)from torchvision.transforms import ToTensor, Compose, Normalize, Resize, InterpolationMode\n",
    "\n",
    "    print(im.shape)\n",
    "    # Resize the CAM mask to match the image size\n",
    "    cam_mask = interpolate(cam_mask, size=im.shape, mode='nearest').squeeze(0)\n",
    "    print(im.shape)\n",
    "    print(cam_mask.shape)\n",
    "    # Convert CAM mask to heatmap\n",
    "    heatmap = plt.get_cmap('jet')(cam_mask.cpu().detach().numpy())[:, :, :3]  # Get the RGB part, discard alpha\n",
    "    heatmap = torch.from_numpy(heatmap).permute(2, 0, 1).float()\n",
    "\n",
    "    # Overlay the heatmap on the image\n",
    "    combined_img = heatmap * 0.3 + im.cpu() * 0.5  # Adjust opacity as needed\n",
    "\n",
    "    return combined_img"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af1903acbac15b5a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# from pytorch_grad_cam import GradCAM\n",
    "\n",
    "import torch\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "grad_cam_c = False\n",
    "samp_batch_idx = [i for i in range(0, len(sample_ids))]\n",
    "random.shuffle(samp_batch_idx)\n",
    "samp_batch_idx = np.array(samp_batch_idx)\n",
    "n = 5\n",
    "\n",
    "for param in model_eval.backbone.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "\n",
    "# target_layer = [model_eval.backbone.layer4[-1].conv1]\n",
    "\n",
    "\n",
    "for batch_start in range(0, n*8, 8):  # Iterate in steps of 8\n",
    "    fig, axs = plt.subplots(2, 4, figsize=(20, 10))  # Create a new figure for each batch\n",
    "    axs = axs.flatten()  # Flatten the grid for easy iteration\n",
    "\n",
    "    for idx, ax in zip(samp_batch_idx[batch_start:batch_start+8], axs):\n",
    "        pred = predictions[idx]\n",
    "        samp_id = sample_ids[idx]\n",
    "        \n",
    "        im_path = f\"../data/test/NoLabel/test_{samp_id}.npy\"\n",
    "        # img = images[idx].unsqueeze(0).requires_grad_(True).to(device)\n",
    "        img = np.load(im_path).transpose(2, 0, 1)\n",
    "        img = img[CHANNELS].astype(np.float32)\n",
    "        \n",
    "        rgb_min, rgb_max = img.min(), img.max()\n",
    "        img = (img - rgb_min) / (rgb_max - rgb_min)\n",
    "        img = img.clip(0, 1)\n",
    "        \n",
    "        \n",
    "        if grad_cam_c:\n",
    "            pass\n",
    "            # img = images[idx].unsqueeze(0).requires_grad_(True).to(device)\n",
    "            # cam = GradCAM(model=model_eval, target_layers=target_layer)\n",
    "            # grayscale_cam = cam(input_tensor=img, targets=None)\n",
    "            # cam_mask_tensor = torch.tensor(grayscale_cam).unsqueeze(0)\n",
    "            # ax.imshow(cam_mask_tensor.squeeze(0).squeeze(0).cpu().numpy(), cmap='jet', alpha=0.1)\n",
    "        else:\n",
    "            ax.imshow(img.transpose(1, 2, 0))\n",
    "        ax.set_title(pred, fontsize=20)\n",
    "        ax.axis('off')\n",
    "        \n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(wspace=0.2, hspace=0.2)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e11bec6bf308538",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3e98d855fa7c2c67"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
