{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Load the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c96e1dbdb152f98"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-13T14:14:56.747834Z",
     "start_time": "2024-03-13T14:14:56.737052Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.colors import bcolors\n",
    "from config import Config\n",
    "\n",
    "c = bcolors()\n",
    "config = Config()\n",
    "\n",
    "CKPT_PATH = 'checkpoints/cnn/'"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import kornia.augmentation as K\n",
    "import torch\n",
    "from src.pickle_loader import load_object, save_object\n",
    "\n",
    "stats = load_object(\"data/eurosat_ms_mean_std\")\n",
    "mean = stats['mean']\n",
    "std = stats['std']\n",
    "chan_idx = stats['idx']\n",
    "\n",
    "CHANNELS = [12, 11, 8, 7]\n",
    "# CHANNELS = [3, 2, 1]\n",
    "NUM_CLASSES = 10\n",
    "NUM_AUG = 1\n",
    "\n",
    "df = pd.read_csv(config.TRAIN_FILE)\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "encoder = encoder.fit(df[['label']].values.reshape(-1, 1))\n",
    "save_object(encoder, \"data/on_hot_encoder\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T14:15:02.750721Z",
     "start_time": "2024-03-13T14:14:56.768568Z"
    }
   },
   "id": "ea2db869e77d2168",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AnnualCrop' 'Forest' 'HerbaceousVegetation' 'Highway' 'Industrial'\n",
      " 'Pasture' 'PermanentCrop' 'Residential' 'River' 'SeaLake']\n",
      "\n",
      "\u001B[92mPreloading images...\u001B[0m\n",
      "\n",
      "\u001B[96mImages:         21600\u001B[0m\n",
      "\u001B[96mAugmentations:  21600\u001B[0m\n",
      "\u001B[96mJobs:           -4 \u001B[0m\n",
      "\n",
      "\u001B[94mTime taken:      0 min 27.359724283218384 sec \u001B[0m\n",
      "\n",
      "\u001B[92mPreloading images...\u001B[0m\n",
      "\n",
      "\u001B[96mImages:         3780\u001B[0m\n",
      "\u001B[96mAugmentations:  3780\u001B[0m\n",
      "\u001B[96mJobs:           -4 \u001B[0m\n",
      "\n",
      "\u001B[94mTime taken:      0 min 2.938011884689331 sec \u001B[0m\n",
      "\n",
      "\u001B[92mPreloading images...\u001B[0m\n",
      "\n",
      "\u001B[96mImages:         1620\u001B[0m\n",
      "\u001B[96mAugmentations:  1620\u001B[0m\n",
      "\u001B[96mJobs:           -4 \u001B[0m\n",
      "\n",
      "\u001B[94mTime taken:      0 min 1.272264003753662 sec \u001B[0m\n",
      "\n",
      "\u001B[96mTrain dataset:   21600 samples\u001B[0m\n",
      "\u001B[96mValidation dataset: 3780 samples\u001B[0m\n",
      "\u001B[96mTest dataset:       1620 samples\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from src.datasets.EuroSatMS import EuroSatMS\n",
    "\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['label'])\n",
    "print(df['label'].unique())\n",
    "test_df, val_df = train_test_split(val_df, test_size=0.7)\n",
    "\n",
    "ds_train = EuroSatMS(\n",
    "    train_df, \n",
    "    config.TRAIN_MS_DIR,\n",
    "    encoder=encoder,\n",
    "    num_aug=NUM_AUG, \n",
    "    select_chan=CHANNELS\n",
    ")\n",
    "\n",
    "ds_val = EuroSatMS(\n",
    "    val_df, \n",
    "    config.TRAIN_MS_DIR,\n",
    "    encoder=encoder,\n",
    "    num_aug=NUM_AUG, \n",
    "    select_chan=CHANNELS\n",
    ")\n",
    "\n",
    "ds_test = EuroSatMS(\n",
    "    test_df, \n",
    "    config.TRAIN_MS_DIR,\n",
    "    encoder=encoder,\n",
    "    num_aug=NUM_AUG, \n",
    "    select_chan=CHANNELS\n",
    ")\n",
    "\n",
    "print(f\"\"\"\\n{c.OKCYAN}Train dataset:   {len(ds_train)} samples{c.ENDC}\"\"\")\n",
    "print(f\"\"\"{c.OKCYAN}Validation dataset: {len(ds_val)} samples{c.ENDC}\"\"\")\n",
    "print(f\"\"\"{c.OKCYAN}Test dataset:       {len(ds_test)} samples{c.ENDC}\"\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T14:15:34.550980Z",
     "start_time": "2024-03-13T14:15:02.754165Z"
    }
   },
   "id": "89850dd26de91e3a",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "transform_mean_std = transforms.Compose([\n",
    "    K.Normalize(mean=mean[CHANNELS], std=std[CHANNELS])\n",
    "])\n",
    "\n",
    "transform_pt = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "p1 = 0.4\n",
    "p2 = 0.6\n",
    "p3 = 0.5\n",
    "augmentation = nn.Sequential(\n",
    "    K.RandomHorizontalFlip(p=p3),\n",
    "    K.RandomVerticalFlip(p=p3),\n",
    "    K.RandomAffine(degrees=45, translate=None, scale=None, shear=None, resample=\"nearest\", padding_mode=2, p=p2),\n",
    "    K.RandomShear(shear=0.3, resample=\"nearest\", padding_mode=2, p=p2),\n",
    "    #K.RandomContrast(contrast=(0.5, 1.5), p=p2),\n",
    "    K.RandomBrightness((0.7, 1.3), p=p2),\n",
    "    #K.RandomPlasmaContrast(p=p1),\n",
    "    #K.RandomSolarize(thresholds=0.01, p=p1),\n",
    "    #K.RandomSharpness(sharpness=0.9, p=p1),\n",
    "    K.RandomSharpness(sharpness=0.8, p=p1),\n",
    "    #K.RandomSharpness(sharpness=0.5, p=p1),\n",
    "    #K.RandomSaturation(p=p1),\n",
    "    # K.RandomBoxBlur(kernel_size=(3, 3), p=p2),\n",
    "    #K.RandomEqualize(p=p1),\n",
    "    K.CenterCrop(size=(64, 64))\n",
    ")\n",
    "\n",
    "ds_train.augment = augmentation\n",
    "ds_val.augment = augmentation\n",
    "ds_test.augment = None\n",
    "\n",
    "ds_train.transform = None\n",
    "ds_val.transform = None\n",
    "ds_test.transform = None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T14:15:34.599216Z",
     "start_time": "2024-03-13T14:15:34.552085Z"
    }
   },
   "id": "a5e5a55b27ee41b1",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 64, 64])\n",
      "\u001B[92mInitialized the data module...\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "from src.training.data import EuroSatDataModule\n",
    "\n",
    "print(ds_val[0][0].shape)\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "data_module = EuroSatDataModule(ds_train, ds_val, ds_test, BATCH_SIZE)\n",
    "print(f\"\"\"{c.OKGREEN}Initialized the data module...{c.ENDC}\"\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T14:15:35.686661Z",
     "start_time": "2024-03-13T14:15:34.600648Z"
    }
   },
   "id": "9471ef6f17ba66c1",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CNN Model Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "693660b793045e2a"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name:  cnn_c121187_k53_lr0.03_m0.9_g0.9_d0.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "KERNEL_SIZE = [5, 3]\n",
    "LEARNING_RATE = 0.03\n",
    "MOMENTUM = 0.9\n",
    "GAMMA = 0.9\n",
    "DROPOUT = 0.3\n",
    "EPOCHS = 15\n",
    "CLASS_WEIGHTS = {'AnnualCrop': 9,\n",
    "                 'Forest': 9,\n",
    "                 'HerbaceousVegetation': 8, \n",
    "                 'Highway': 9, \n",
    "                 'Industrial': 9,\n",
    "                 'Pasture': 9, \n",
    "                 'PermanentCrop': 9, \n",
    "                 'Residential': 9, \n",
    "                 'River': 9, \n",
    "                 'SeaLake': 9}\n",
    "\n",
    "w = np.array(list(CLASS_WEIGHTS.values()))\n",
    "w_min, w_max = w.min(), w.max()\n",
    "w = (w - w_min) / (w_max - w_min)\n",
    "\n",
    "fname = \"cnn_c\"\n",
    "for c in CHANNELS:\n",
    "    fname += str(c)\n",
    "fname += \"_k\"\n",
    "for k in KERNEL_SIZE:\n",
    "    fname += str(k)\n",
    "fname += \"_lr\" + str(LEARNING_RATE)\n",
    "fname += \"_m\" + str(MOMENTUM)\n",
    "fname += \"_g\" + str(GAMMA)\n",
    "fname += \"_d\" + str(DROPOUT)\n",
    "\n",
    "print(\"Model name: \", fname)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T14:15:35.692400Z",
     "start_time": "2024-03-13T14:15:35.687660Z"
    }
   },
   "id": "ccb6a56d1d57dfe3",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 40\u001B[0m\n\u001B[1;32m     24\u001B[0m checkpoint_callback \u001B[38;5;241m=\u001B[39m ModelCheckpoint(\n\u001B[1;32m     25\u001B[0m     dirpath\u001B[38;5;241m=\u001B[39mCKPT_PATH \u001B[38;5;241m+\u001B[39m datetime\u001B[38;5;241m.\u001B[39mnow()\u001B[38;5;241m.\u001B[39mstrftime(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mH-\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mM\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m     26\u001B[0m     filename\u001B[38;5;241m=\u001B[39mfname \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m{ep:02d}\u001B[39;00m\u001B[38;5;124m-\u001B[39m\u001B[38;5;132;01m{val_l:.2f}\u001B[39;00m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     29\u001B[0m     verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m     30\u001B[0m )\n\u001B[1;32m     32\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Trainer(\n\u001B[1;32m     33\u001B[0m     max_epochs\u001B[38;5;241m=\u001B[39mEPOCHS,\n\u001B[1;32m     34\u001B[0m     accelerator\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgpu\u001B[39m\u001B[38;5;124m\"\u001B[39m, \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     37\u001B[0m     callbacks\u001B[38;5;241m=\u001B[39m[checkpoint_callback],\n\u001B[1;32m     38\u001B[0m )\n\u001B[0;32m---> 40\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlightning_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatamodule\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_module\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/Uni/SS24/ML/EuroSat_Dataset_LUC/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:544\u001B[0m, in \u001B[0;36mTrainer.fit\u001B[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[1;32m    542\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m=\u001B[39m TrainerStatus\u001B[38;5;241m.\u001B[39mRUNNING\n\u001B[1;32m    543\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m--> 544\u001B[0m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_and_handle_interrupt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    545\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_impl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatamodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\n\u001B[1;32m    546\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/Uni/SS24/ML/EuroSat_Dataset_LUC/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:44\u001B[0m, in \u001B[0;36m_call_and_handle_interrupt\u001B[0;34m(trainer, trainer_fn, *args, **kwargs)\u001B[0m\n\u001B[1;32m     42\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     43\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher\u001B[38;5;241m.\u001B[39mlaunch(trainer_fn, \u001B[38;5;241m*\u001B[39margs, trainer\u001B[38;5;241m=\u001B[39mtrainer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m---> 44\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtrainer_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _TunerExitException:\n\u001B[1;32m     47\u001B[0m     _call_teardown_hook(trainer)\n",
      "File \u001B[0;32m~/Desktop/Uni/SS24/ML/EuroSat_Dataset_LUC/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:580\u001B[0m, in \u001B[0;36mTrainer._fit_impl\u001B[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[1;32m    573\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    574\u001B[0m ckpt_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_checkpoint_connector\u001B[38;5;241m.\u001B[39m_select_ckpt_path(\n\u001B[1;32m    575\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn,\n\u001B[1;32m    576\u001B[0m     ckpt_path,\n\u001B[1;32m    577\u001B[0m     model_provided\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    578\u001B[0m     model_connected\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    579\u001B[0m )\n\u001B[0;32m--> 580\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mckpt_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    582\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstopped\n\u001B[1;32m    583\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/Uni/SS24/ML/EuroSat_Dataset_LUC/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:943\u001B[0m, in \u001B[0;36mTrainer._run\u001B[0;34m(self, model, ckpt_path)\u001B[0m\n\u001B[1;32m    939\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[1;32m    940\u001B[0m \u001B[38;5;66;03m# SET UP THE TRAINER\u001B[39;00m\n\u001B[1;32m    941\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[1;32m    942\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: setting up strategy environment\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 943\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstrategy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msetup_environment\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    944\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__setup_profiler()\n\u001B[1;32m    946\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: preparing data\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Desktop/Uni/SS24/ML/EuroSat_Dataset_LUC/.venv/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py:129\u001B[0m, in \u001B[0;36mStrategy.setup_environment\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    122\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Setup any processes or distributed connections.\u001B[39;00m\n\u001B[1;32m    123\u001B[0m \n\u001B[1;32m    124\u001B[0m \u001B[38;5;124;03mThis is called before the LightningModule/DataModule setup hook which allows the user to access the accelerator\u001B[39;00m\n\u001B[1;32m    125\u001B[0m \u001B[38;5;124;03menvironment before setup is complete.\u001B[39;00m\n\u001B[1;32m    126\u001B[0m \n\u001B[1;32m    127\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    128\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccelerator \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 129\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maccelerator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msetup_device\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mroot_device\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/Uni/SS24/ML/EuroSat_Dataset_LUC/.venv/lib/python3.11/site-packages/pytorch_lightning/accelerators/cuda.py:46\u001B[0m, in \u001B[0;36mCUDAAccelerator.setup_device\u001B[0;34m(self, device)\u001B[0m\n\u001B[1;32m     44\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m device\u001B[38;5;241m.\u001B[39mtype \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m     45\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MisconfigurationException(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDevice should be GPU, got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdevice\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m instead\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 46\u001B[0m \u001B[43m_check_cuda_matmul_precision\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     47\u001B[0m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mset_device(device)\n",
      "File \u001B[0;32m~/Desktop/Uni/SS24/ML/EuroSat_Dataset_LUC/.venv/lib/python3.11/site-packages/lightning_fabric/accelerators/cuda.py:361\u001B[0m, in \u001B[0;36m_check_cuda_matmul_precision\u001B[0;34m(device)\u001B[0m\n\u001B[1;32m    359\u001B[0m \u001B[38;5;129m@lru_cache\u001B[39m(\u001B[38;5;241m1\u001B[39m)  \u001B[38;5;66;03m# show the warning only ever once\u001B[39;00m\n\u001B[1;32m    360\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_check_cuda_matmul_precision\u001B[39m(device: torch\u001B[38;5;241m.\u001B[39mdevice) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 361\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available() \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[43m_is_ampere_or_later\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m    362\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m    363\u001B[0m     \u001B[38;5;66;03m# check that the user hasn't changed the precision already, this works for both `allow_tf32 = True` and\u001B[39;00m\n\u001B[1;32m    364\u001B[0m     \u001B[38;5;66;03m# `set_float32_matmul_precision`\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/Uni/SS24/ML/EuroSat_Dataset_LUC/.venv/lib/python3.11/site-packages/lightning_fabric/accelerators/cuda.py:355\u001B[0m, in \u001B[0;36m_is_ampere_or_later\u001B[0;34m(device)\u001B[0m\n\u001B[1;32m    354\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_is_ampere_or_later\u001B[39m(device: Optional[torch\u001B[38;5;241m.\u001B[39mdevice] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mbool\u001B[39m:\n\u001B[0;32m--> 355\u001B[0m     major, _ \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_device_capability\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    356\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m major \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m8\u001B[39m\n",
      "File \u001B[0;32m~/Desktop/Uni/SS24/ML/EuroSat_Dataset_LUC/.venv/lib/python3.11/site-packages/torch/cuda/__init__.py:439\u001B[0m, in \u001B[0;36mget_device_capability\u001B[0;34m(device)\u001B[0m\n\u001B[1;32m    426\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_device_capability\u001B[39m(device: Optional[_device_t] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[\u001B[38;5;28mint\u001B[39m, \u001B[38;5;28mint\u001B[39m]:\n\u001B[1;32m    427\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Get the cuda capability of a device.\u001B[39;00m\n\u001B[1;32m    428\u001B[0m \n\u001B[1;32m    429\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    437\u001B[0m \u001B[38;5;124;03m        tuple(int, int): the major and minor cuda capability of the device\u001B[39;00m\n\u001B[1;32m    438\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 439\u001B[0m     prop \u001B[38;5;241m=\u001B[39m \u001B[43mget_device_properties\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    440\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m prop\u001B[38;5;241m.\u001B[39mmajor, prop\u001B[38;5;241m.\u001B[39mminor\n",
      "File \u001B[0;32m~/Desktop/Uni/SS24/ML/EuroSat_Dataset_LUC/.venv/lib/python3.11/site-packages/torch/cuda/__init__.py:453\u001B[0m, in \u001B[0;36mget_device_properties\u001B[0;34m(device)\u001B[0m\n\u001B[1;32m    443\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_device_properties\u001B[39m(device: _device_t) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m _CudaDeviceProperties:\n\u001B[1;32m    444\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Get the properties of a device.\u001B[39;00m\n\u001B[1;32m    445\u001B[0m \n\u001B[1;32m    446\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    451\u001B[0m \u001B[38;5;124;03m        _CudaDeviceProperties: the properties of the device\u001B[39;00m\n\u001B[1;32m    452\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 453\u001B[0m     \u001B[43m_lazy_init\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# will define _get_device_properties\u001B[39;00m\n\u001B[1;32m    454\u001B[0m     device \u001B[38;5;241m=\u001B[39m _get_device_index(device, optional\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    455\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m device \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m device \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m device_count():\n",
      "File \u001B[0;32m~/Desktop/Uni/SS24/ML/EuroSat_Dataset_LUC/.venv/lib/python3.11/site-packages/torch/cuda/__init__.py:302\u001B[0m, in \u001B[0;36m_lazy_init\u001B[0;34m()\u001B[0m\n\u001B[1;32m    300\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCUDA_MODULE_LOADING\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m os\u001B[38;5;241m.\u001B[39menviron:\n\u001B[1;32m    301\u001B[0m     os\u001B[38;5;241m.\u001B[39menviron[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCUDA_MODULE_LOADING\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLAZY\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m--> 302\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_cuda_init\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    303\u001B[0m \u001B[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001B[39;00m\n\u001B[1;32m    304\u001B[0m \u001B[38;5;66;03m# we need to just return without initializing in that case.\u001B[39;00m\n\u001B[1;32m    305\u001B[0m \u001B[38;5;66;03m# However, we must not let any *other* threads in!\u001B[39;00m\n\u001B[1;32m    306\u001B[0m _tls\u001B[38;5;241m.\u001B[39mis_initializing \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero."
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import BackboneFinetuning, ModelCheckpoint\n",
    "from src.training.cnn import LitEuroSatCnn\n",
    "from datetime import datetime\n",
    "\n",
    "lightning_model = LitEuroSatCnn(\n",
    "    num_classes=NUM_CLASSES,\n",
    "    learning_rate=LEARNING_RATE, \n",
    "    num_channels=len(CHANNELS), \n",
    "    kernel_size=KERNEL_SIZE,\n",
    "    momentum=MOMENTUM,\n",
    "    gamma=GAMMA,\n",
    "    weights=torch.tensor(w, dtype=torch.float32),\n",
    "    dropout=DROPOUT\n",
    ")\n",
    "\n",
    "logger = WandbLogger(\n",
    "    project=\"eurosat_cnn\",\n",
    "    name=\"cnn_v1\",\n",
    "    log_model=False,\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=CKPT_PATH + datetime.now().strftime(\"%H-%M\"),\n",
    "    filename=fname + '_{ep:02d}-{val_l:.2f}',\n",
    "    save_top_k=2, \n",
    "    monitor=\"val_loss\",\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=EPOCHS,\n",
    "    accelerator=\"gpu\", \n",
    "    devices=1,\n",
    "    logger=logger,\n",
    "    callbacks=[checkpoint_callback],\n",
    ")\n",
    "\n",
    "trainer.fit(lightning_model, datamodule=data_module)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T14:15:36.815346Z",
     "start_time": "2024-03-13T14:15:35.693877Z"
    }
   },
   "id": "fa70fc0415fe6817",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "trainer.test(lightning_model, datamodule=data_module, ckpt_path=checkpoint_callback.best_model_path)\n",
    "metric = torchmetrics.ConfusionMatrix(task=\"multiclass\", num_classes=NUM_CLASSES)\n",
    "all_preds = np.concatenate(lightning_model.ep_out)\n",
    "all_true = np.concatenate(lightning_model.ep_true)\n",
    "true_ep = torch.tensor(all_true)\n",
    "pred_ep = torch.tensor(all_preds)\n",
    "metric.update(pred_ep, true_ep)\n",
    "fig, ax = metric.plot()\n",
    "plt.show()\n",
    "print(encoder.categories_[0])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2bb7804baa9a7fa0",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2e31138fe1fbd612"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pretrained Model Training\n",
    "### Training Phase 1\n",
    "##### Pretrained ResNet50, ResNet18, AlexNet Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7460c6672b1ff7c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torchgeo.models as models\n",
    "from torchgeo.models import ResNet18_Weights, ResNet50_Weights\n",
    "\n",
    "\n",
    "def get_pretrained_model(model_name):\n",
    "    if model_name == \"B13_rn50_moco_0099\":\n",
    "        m = models.resnet50(weights=None)\n",
    "        m.fc = nn.Linear(2048,19)\n",
    "        m.conv1 = nn.Conv2d(\n",
    "            13, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
    "        )\n",
    "        ckp = torch.load(\"B13_rn50_moco_0099.pth\", map_location=\"cpu\")\n",
    "        sd = ckp['state_dict']\n",
    "        \n",
    "        for key in list(sd.keys()):\n",
    "            if key.startswith('module.encoder_q') and not key.startswith('module.encoder_q.fc'):\n",
    "                sd[key[len(\"module.encoder_q.\"):]] = sd[key]\n",
    "            del sd[key]\n",
    "        \n",
    "        msg = m.load_state_dict(sd, strict=False)\n",
    "        assert set(msg.missing_keys) == {\"fc.weight\", \"fc.bias\"}\n",
    "        \n",
    "        return m\n",
    "    elif \"resnet18_RGB_MOCO\" in model_name:\n",
    "        return models.resnet18(weights=ResNet18_Weights.SENTINEL2_RGB_MOCO)\n",
    "    elif \"resnet50_RGB_MOCO\" in model_name:\n",
    "        return models.resnet50(weights=ResNet50_Weights.SENTINEL2_RGB_MOCO)\n",
    "\n",
    "m_name = \"resnet18_RGB_MOCO\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a7506054d07ddabd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import BackboneFinetuning, ModelCheckpoint\n",
    "from pytorch_lightning import Trainer\n",
    "from src.training.pretrainedModels import EuroSatPreTrainedModel\n",
    "\n",
    "model = get_pretrained_model(m_name)\n",
    "\n",
    "model_train = EuroSatPreTrainedModel(\n",
    "    backbone=model,\n",
    "    learning_rate=0.03,\n",
    "    gamma=0.9,\n",
    "    momentum=0.9,\n",
    "    dropout=0.2,\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "logger = WandbLogger(\n",
    "    project=\"eurosat_resnet\",\n",
    "    name=\"resnet_pretrained_v1\",\n",
    "    log_model=False,\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=CKPT_PATH + datetime.now().strftime(\"%H-%M\"),\n",
    "    save_top_k=1, \n",
    "    monitor=\"val_loss\",\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=5,\n",
    "    accelerator=\"gpu\", \n",
    "    devices=1,\n",
    "    logger=logger,\n",
    "    callbacks=[checkpoint_callback],\n",
    ")\n",
    "\n",
    "trainer.fit(model_train, datamodule=data_module)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "efb3d4dce1d9c8f8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "trainer.test(model_train, datamodule=data_module, ckpt_path=checkpoint_callback.best_model_path)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aed3e9933094cba9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = get_pretrained_model(m_name)\n",
    "\n",
    "model_train = EuroSatPreTrainedModel.load_from_checkpoint(\n",
    "    checkpoint_callback.best_model_path,\n",
    "    backbone=model,\n",
    "    freeze_backbone=False,\n",
    "    learning_rate=0.0001,\n",
    "    gamma=0.7,\n",
    "    momentum=0.9,\n",
    "    dropout=0.3,\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "logger = WandbLogger(\n",
    "    project=\"eurosat_resnet\",\n",
    "    name=\"resnet18_p2\",\n",
    "    log_model=False,\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=CKPT_PATH + datetime.now().strftime(\"%H-%M\"),\n",
    "    save_top_k=1, \n",
    "    monitor=\"val_loss\",\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=3,\n",
    "    accelerator=\"gpu\", \n",
    "    devices=1,\n",
    "    logger=logger,\n",
    "    callbacks=[checkpoint_callback],\n",
    ")\n",
    "\n",
    "trainer.fit(model_train, datamodule=data_module)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a1527d13a0bd2e9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "trainer.test(model_train, datamodule=data_module, ckpt_path=checkpoint_callback.best_model_path)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28a7c062d1e82c9e",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Predict on the test set"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d14c14d786b83fa8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from src.datasets.EuroSatTest import EuroSatTestSet\n",
    "from torch.utils.data import DataLoader\n",
    "from config import Config\n",
    "\n",
    "config = Config()\n",
    "\n",
    "# CHANNELS = [11, 10, 8, 7, 6, 5, 4, 3, 2, 1, 0]\n",
    "CHANNELS = [8, 7, 6, 5, 4]\n",
    "\n",
    "dataset = EuroSatTestSet(config.TEST_MS_DIR, select_chan=CHANNELS, add_b10=False) #, augment=aug)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=False)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fbe578b12c3ba259",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from src.training.pretrainedModels import EuroSatPreTrainedModel\n",
    "from src.training.cnn import LitEuroSatCnn\n",
    "from config import Config\n",
    "\n",
    "config = Config()\n",
    "\n",
    "model_eval = LitEuroSatCnn.load_from_checkpoint(\n",
    "    \"checkpoints/cnn/14-18/cnn_c87654_k53_lr0.03_m0.9_g0.8epoch=09-val_loss=0.68.ckpt\", #checkpoint_callback.best_model_path,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    learning_rate=0.025, \n",
    "    num_channels=len(CHANNELS), \n",
    "    kernel_size=[5, 3],\n",
    "    momentum=0.9,\n",
    "    gamma=0.9,\n",
    "    weights=torch.tensor(w, dtype=torch.float32)\n",
    ")\n",
    "\n",
    "\n",
    "# model = get_pretrained_model(m_name)\n",
    "# model_eval = EuroSatPreTrainedModel.load_from_checkpoint(\n",
    "#     checkpoint_callback.best_model_path,\n",
    "#     backbone=model,\n",
    "#     learning_rate=1e-4,\n",
    "#     momentum=0.9,\n",
    "#     dropout=0,\n",
    "#     weight_decay=0.0001\n",
    "# )\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model_eval.eval()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b042a06f7a52870c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_eval = model_eval.to(device)\n",
    "model_eval.eval()\n",
    "\n",
    "N_CLASSES = 10\n",
    "categorys = encoder.categories_[0]\n",
    "print(categorys)\n",
    "\n",
    "predictions = []\n",
    "probabilities = []\n",
    "ohe = []\n",
    "images = []\n",
    "sample_ids = []\n",
    "\n",
    "rounds = 3\n",
    "\n",
    "    \n",
    "with torch.no_grad():\n",
    "    for batch in dataloader:\n",
    "        inputs, samp_id = batch\n",
    "        inputs = inputs.to(device)\n",
    "        # for rounds predict inputs and select the most frequent prediction\n",
    "        # round_preds = []\n",
    "        # for r in range(rounds):\n",
    "        #     inp = augmentation(inputs)\n",
    "        #     outputs = model_eval(inp)\n",
    "        #     _, preds = torch.max(outputs, 1)\n",
    "        #     round_preds.append(preds.cpu().numpy())\n",
    "        # \n",
    "        # round_preds = np.array(round_preds).T\n",
    "        # preds = []\n",
    "        # for i in range(round_preds.shape[0]):\n",
    "        #     t, c = np.unique(round_preds[i], return_counts=True)\n",
    "        #     preds.append(int(t[np.argmax(c)]))\n",
    "            \n",
    "        outputs = model_eval(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        preds = np.array(preds.cpu().numpy())\n",
    "            \n",
    "        # preds_enc = np.zeros((preds.size, N_CLASSES))\n",
    "        # preds_enc[np.arange(preds.size), preds] = 1\n",
    "        \n",
    "        pred_labels = np.array([categorys[p] for p in preds])\n",
    "        # true_labels = np.array([categorys[np.argmax(p)] for p in samp_id.cpu().numpy()])\n",
    "        \n",
    "        predictions.extend(pred_labels)\n",
    "        images.extend(inputs.cpu())\n",
    "        sample_ids.extend(samp_id.cpu())\n",
    "        # probabilities.extend(probs.cpu())\n",
    "        # true_l.extend(true_labels)\n",
    "        # ohe.extend(preds_enc)\n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "194979db7753d23d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "sub_df = pd.DataFrame({'test_id': np.array(sample_ids), 'label': np.array(predictions)})\n",
    "sub_df = sub_df.sort_values(by='test_id')\n",
    "print(sub_df.head())\n",
    "print(np.array(sample_ids))\n",
    "\n",
    "sub_df.to_csv('submission.csv', index=False)\n",
    "print(np.unique(predictions, return_counts=True))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "58b692ad612e50fa",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "samp_batch_idx = [i for i in range(0, len(sample_ids))]\n",
    "random.shuffle(samp_batch_idx)\n",
    "samp_batch_idx = np.array(samp_batch_idx)\n",
    "n = 5\n",
    "\n",
    "\n",
    "for batch_start in range(0, n*8, 8):  # Iterate in steps of 8\n",
    "    fig, axs = plt.subplots(2, 4, figsize=(20, 10))  # Create a new figure for each batch\n",
    "    axs = axs.flatten()  # Flatten the grid for easy iteration\n",
    "\n",
    "    for idx, ax in zip(samp_batch_idx[batch_start:batch_start+8], axs):\n",
    "        pred = predictions[idx]\n",
    "        samp_id = sample_ids[idx]\n",
    "        \n",
    "        im_path = f\"data/test/NoLabel/test_{samp_id}.npy\"\n",
    "        img = images[idx].numpy()[[1, 2, 3]].transpose(1, 2, 0)\n",
    "        \n",
    "        # img = np.load(im_path).transpose(2, 0, 1)\n",
    "        # img = img[[3, 2, 1]].astype(np.float32)\n",
    "        # \n",
    "        # \n",
    "        # # Normalize the image\n",
    "        # rgb_min, rgb_max = img.min(), img.max()\n",
    "        # img = (img - rgb_min) / (rgb_max - rgb_min)\n",
    "        # \n",
    "        # img = img.transpose(1, 2, 0)\n",
    "\n",
    "        # Plotting\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(pred, fontsize=20)\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(wspace=0.2, hspace=0.2)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92c86ebc6b28bb3b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e2e6f2c3f2784f47"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
